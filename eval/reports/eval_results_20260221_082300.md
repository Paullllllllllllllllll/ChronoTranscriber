# ChronoTranscriber Evaluation Results

**Generated:** 20260221_082300

**Evaluation Method:** Page-level JSONL comparison â€” CER/WER computed after stripping all structural markup

## Models Evaluated

- **tesseract**: Tesseract OCR baseline (no LLM)
- **gpt_5.2_medium**: GPT-5.2 with medium reasoning
- **gpt_5_mini_medium**: GPT-5 Mini with medium reasoning
- **gemini_3.0_pro_medium**: Gemini 3 Pro Preview with medium reasoning
- **gemini_3.0_flash**: Gemini 3 Flash Preview
- **claude_sonnet_4.5_medium**: Claude Sonnet 4.5 with medium reasoning
- **claude_haiku_4.5_medium**: Claude Haiku 4.5 with medium reasoning

## Results by Category

| Model | Category | CER (%) | WER (%) | Ref Chars |
|-------|----------|---------|---------|-----------|
| claude_haiku_4.5_medium | address_books | 7.88 | 35.48 | 99,393 |
| claude_haiku_4.5_medium | bibliography | 6.95 | 12.58 | 64,541 |
| claude_haiku_4.5_medium | military_records | 34.65 | 63.82 | 2,892 |
| claude_sonnet_4.5_medium | address_books | 5.28 | 20.27 | 99,393 |
| claude_sonnet_4.5_medium | bibliography | 6.53 | 12.38 | 64,541 |
| claude_sonnet_4.5_medium | military_records | 26.35 | 37.19 | 2,892 |
| gemini_3.0_flash | address_books | 6.44 | 20.20 | 99,393 |
| gemini_3.0_flash | bibliography | 6.30 | 10.58 | 64,541 |
| gemini_3.0_flash | military_records | 38.11 | 50.00 | 2,892 |
| gemini_3.0_pro_medium | address_books | 1.91 | 16.06 | 99,393 |
| gemini_3.0_pro_medium | bibliography | 6.49 | 12.30 | 64,541 |
| gemini_3.0_pro_medium | military_records | 86.20 | 102.76 | 2,892 |
| gpt_5.2_medium | address_books | 5.47 | 28.99 | 99,393 |
| gpt_5.2_medium | bibliography | 5.93 | 8.38 | 64,541 |
| gpt_5.2_medium | military_records | 24.79 | 31.91 | 2,892 |
| gpt_5_mini_medium | address_books | 5.70 | 33.61 | 99,393 |
| gpt_5_mini_medium | bibliography | 41.46 | 45.51 | 64,541 |
| gpt_5_mini_medium | military_records | 24.27 | 40.70 | 2,892 |
| tesseract | address_books | 87.89 | 145.17 | 99,393 |
| tesseract | bibliography | 9.43 | 18.71 | 64,541 |
| tesseract | military_records | 71.54 | 137.69 | 2,892 |

### Formatting Compliance

| Model | Category | Page Tag Recall (%) | Heading Recall (%) | Bold/Italic Ratio (%) |
|-------|----------|---------------------|--------------------|-----------------------|
| claude_haiku_4.5_medium | address_books | 38.7 | 46.7 | 22.8 |
| claude_haiku_4.5_medium | bibliography | 76.7 | 11.4 | 31.0 |
| claude_haiku_4.5_medium | military_records | 0.0 | 66.7 | 5500.0 |
| claude_sonnet_4.5_medium | address_books | 32.3 | 3.3 | 28.9 |
| claude_sonnet_4.5_medium | bibliography | 90.0 | 17.1 | 51.7 |
| claude_sonnet_4.5_medium | military_records | 100.0 | 66.7 | 2100.0 |
| gemini_3.0_flash | address_books | 93.5 | 3.3 | 74.6 |
| gemini_3.0_flash | bibliography | 100.0 | 17.1 | 113.8 |
| gemini_3.0_flash | military_records | 300.0 | 66.7 | 3400.0 |
| gemini_3.0_pro_medium | address_books | 96.8 | 13.3 | 95.3 |
| gemini_3.0_pro_medium | bibliography | 93.3 | 5.7 | 63.8 |
| gemini_3.0_pro_medium | military_records | 0.0 | 100.0 | 200.0 |
| gpt_5.2_medium | address_books | 3.2 | 0.0 | 0.6 |
| gpt_5.2_medium | bibliography | 100.0 | 2.9 | 5.2 |
| gpt_5.2_medium | military_records | 100.0 | 66.7 | 0.0 |
| gpt_5_mini_medium | address_books | 22.6 | 20.0 | 0.3 |
| gpt_5_mini_medium | bibliography | 60.0 | 0.0 | 24.1 |
| gpt_5_mini_medium | military_records | 100.0 | 100.0 | 0.0 |
| tesseract | address_books | 0.0 | 0.0 | 5.3 |
| tesseract | bibliography | 0.0 | 0.0 | 3.4 |
| tesseract | military_records | 0.0 | 0.0 | 100.0 |

## Overall Rankings (Pure CER)

| Rank | Model | CER (%) | WER (%) |
|------|-------|---------|--------|
| 1 | gemini_3.0_pro_medium | 5.15 | 15.74 |
| 2 | gpt_5.2_medium | 5.98 | 19.49 |
| 3 | claude_sonnet_4.5_medium | 6.13 | 16.90 |
| 4 | gemini_3.0_flash | 6.93 | 16.23 |
| 5 | claude_haiku_4.5_medium | 7.98 | 25.33 |
| 6 | gpt_5_mini_medium | 19.86 | 39.24 |
| 7 | tesseract | 57.25 | 86.47 |
