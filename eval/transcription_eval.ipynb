{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChronoTranscriber Evaluation: CER & WER Analysis\n",
    "\n",
    "This notebook evaluates transcription quality across multiple transcription systems (local OCR and multiple LLM providers) using edit-distance–based accuracy metrics computed against manually corrected ground truth.\n",
    "\n",
    "The primary evaluation outputs are:\n",
    "- **Character Error Rate (CER)**: edit distance at the character level, divided by the number of reference characters.\n",
    "- **Word Error Rate (WER)**: edit distance at the word level, divided by the number of reference words.\n",
    "\n",
    "## Evaluation Method\n",
    "The evaluation is performed **page-by-page** using the temporary JSONL files produced by the ChronoTranscriber pipeline. Page-level evaluation is preferred over comparing final exported plain-text files because it:\n",
    "- Avoids penalizing downstream whitespace or post-processing differences that do not reflect transcription quality.\n",
    "- Preserves page boundaries to support error localization and qualitative inspection.\n",
    "- Enables fairer comparisons across models when outputs vary in formatting.\n",
    "\n",
    "The metrics implementation distinguishes:\n",
    "- **Overall metrics**: computed on the full text (including markup and page markers if present).\n",
    "- **Content-only metrics**: computed after removing formatting artifacts to focus on raw text recognition.\n",
    "- **Formatting metrics** (available in the underlying metric implementation): separate accounting for page markers and common Markdown constructs.\n",
    "\n",
    "## Models Evaluated\n",
    "| Provider | Model | `model_id` | Reasoning |\n",
    "|----------|-------|-----------|----------|\n",
    "| Local | Tesseract OCR | `tesseract` | None (baseline) |\n",
    "| OpenAI | GPT-5.2 | `gpt-5.2` | Medium |\n",
    "| OpenAI | GPT-5 Mini | `gpt-5-mini` | Medium |\n",
    "| Google | Gemini 3 Pro | `gemini-3-pro` | Medium |\n",
    "| Google | Gemini 3 Flash | `gemini-3-flash-preview` | None |\n",
    "| Anthropic | Claude Sonnet 4.5 | `claude-sonnet-4-5-20250929` | Medium |\n",
    "| Anthropic | Claude Haiku 4.5 | `claude-haiku-4-5` | Medium |\n",
    "\n",
    "## Dataset Categories\n",
    "The evaluation dataset is organized into three document categories defined in the configuration:\n",
    "1. **Address Books** — Swiss address book pages (Basel 1900); 31 pages processed as one source\n",
    "2. **Bibliography** — European culinary bibliography (Oxford 1913); 187 pages\n",
    "3. **Military Records** — Brazilian military enlistment cards; 3 sources × 2 pages each\n",
    "\n",
    "## Ground Truth\n",
    "Manually corrected reference transcriptions are stored as JSONL in `test_data/ground_truth/`\n",
    "(converted from `Korrekturen.zip` via `setup_ground_truth.py`). Schema normalizations applied:\n",
    "- Image tags: `[Image: ...]` → `![Image: ...]`\n",
    "- Page markers: `<page_number>X<page_number>` → `<page_number>X</page_number>`\n",
    "\n",
    "## Reproducibility\n",
    "This notebook is designed to be paper-ready and reproducible:\n",
    "- Key result tables are rendered inline as HTML for stable visual inspection in the notebook.\n",
    "- If `SAVE_TABLES_LATEX = True`, tables are also exported as TeX table files to `LATEX_OUTPUT_DIR` with captions and labels suitable for manuscript inclusion.\n",
    "- Run metadata (timestamp and output locations) are printed in the Setup section for provenance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. **Configuration**\n",
    "   Load the evaluation configuration (YAML), resolve all dataset/report paths, and document the run-time settings used for this evaluation.\n",
    "\n",
    "2. **Discover Available Data**\n",
    "   Enumerate available input sources, model output JSONL files, and ground-truth JSONL files to determine which model–category combinations can be evaluated.\n",
    "\n",
    "3. **Page-Level Evaluation**\n",
    "   Define the evaluation data structures and compute page-aligned CER/WER metrics by comparing each model’s JSONL transcription output against ground truth.\n",
    "\n",
    "4. **Results Summary**\n",
    "   Produce paper-ready summary tables (inline HTML; optional LaTeX export) showing model performance by category and overall rankings across categories.\n",
    "\n",
    "5. **Detailed Per-Page Results**\n",
    "   Display (and optionally export) a per-page table for a selected `SHOW_CATEGORY` / `SHOW_MODEL` / `SHOW_SOURCE` to support qualitative inspection and debugging.\n",
    "\n",
    "6. **Export Results**\n",
    "   Save machine-readable artifacts (JSON + CSV + Markdown) into the reports directory for archiving and downstream analysis; show an export summary table.\n",
    "\n",
    "7. **Visualization (Optional)**\n",
    "   Generate a compact figure comparing models on CER and WER; save the plot for figures and optionally as PDF for LaTeX workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T11:09:40.786686Z",
     "iopub.status.busy": "2026-02-27T11:09:40.786236Z",
     "iopub.status.idle": "2026-02-27T11:09:41.256450Z",
     "shell.execute_reply": "2026-02-27T11:09:41.254917Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis run: 2026-02-27 12:09:41\n",
      "Evaluation directory: C:\\Users\\pagoetz\\PycharmProjects\\ChronoTranscriber\\eval\n",
      "Project root: C:\\Users\\pagoetz\\PycharmProjects\\ChronoTranscriber\n",
      "Save tables as LaTeX: True\n",
      "LaTeX output directory: C:\\Users\\pagoetz\\PycharmProjects\\ChronoTranscriber\\eval\\reports\\latex_tables\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Standard library imports\n",
    "# =============================================================================\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# =============================================================================\n",
    "# Data handling and display\n",
    "# =============================================================================\n",
    "import yaml\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# =============================================================================\n",
    "# Path Configuration\n",
    "# =============================================================================\n",
    "EVAL_DIR = Path.cwd()\n",
    "PROJECT_ROOT = EVAL_DIR.parent\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "sys.path.insert(0, str(EVAL_DIR))\n",
    "\n",
    "# =============================================================================\n",
    "# OUTPUT CONFIGURATION\n",
    "# =============================================================================\n",
    "# Set to True to save tables as LaTeX .tex files\n",
    "SAVE_TABLES_LATEX = True\n",
    "\n",
    "# Directory for LaTeX table output (relative to EVAL_DIR)\n",
    "LATEX_OUTPUT_DIR = EVAL_DIR / \"reports\" / \"latex_tables\"\n",
    "\n",
    "# Create output directory if saving LaTeX\n",
    "if SAVE_TABLES_LATEX:\n",
    "    LATEX_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# =============================================================================\n",
    "# Import evaluation metrics\n",
    "# =============================================================================\n",
    "from metrics import (\n",
    "    compute_metrics,\n",
    "    aggregate_metrics,\n",
    "    TranscriptionMetrics,\n",
    "    format_metrics_table,\n",
    ")\n",
    "\n",
    "# Import JSONL page-level utilities\n",
    "from jsonl_eval import (\n",
    "    PageTranscription,\n",
    "    DocumentTranscriptions,\n",
    "    parse_transcription_jsonl,\n",
    "    find_jsonl_file,\n",
    "    load_page_transcriptions,\n",
    "    load_ground_truth_pages,\n",
    "    align_pages,\n",
    ")\n",
    "\n",
    "# =============================================================================\n",
    "# Run Summary\n",
    "# =============================================================================\n",
    "print(f\"Analysis run: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Evaluation directory: {EVAL_DIR}\")\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"Save tables as LaTeX: {SAVE_TABLES_LATEX}\")\n",
    "if SAVE_TABLES_LATEX:\n",
    "    print(f\"LaTeX output directory: {LATEX_OUTPUT_DIR.resolve()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration\n",
    "\n",
    "This section loads the evaluation configuration (YAML) and resolves all key paths used throughout the notebook. The configuration defines:\n",
    "\n",
    "- **Dataset locations**\n",
    "  - `INPUT_PATH`: source documents (images or PDFs), grouped by category.\n",
    "  - `OUTPUT_PATH`: model-generated JSONL transcriptions (the hypothesis).\n",
    "  - `GROUND_TRUTH_PATH`: manually corrected JSONL transcriptions (the reference).\n",
    "  - `REPORTS_PATH`: where exported evaluation artifacts are written.\n",
    "\n",
    "- **Evaluation scope**\n",
    "  - `CATEGORIES`: which dataset categories are included.\n",
    "  - `MODELS`: which model identifiers are available or expected.\n",
    "\n",
    "**Output produced in this section**\n",
    "- **Table 1**: a compact configuration table documenting the paths and scope used for the current run.\n",
    "- Optional: a TeX export of Table 1 saved to `LATEX_OUTPUT_DIR` if `SAVE_TABLES_LATEX = True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T11:09:41.326277Z",
     "iopub.status.busy": "2026-02-27T11:09:41.325491Z",
     "iopub.status.idle": "2026-02-27T11:09:41.478077Z",
     "shell.execute_reply": "2026-02-27T11:09:41.476396Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Table 1: Evaluation Configuration</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Parameter</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Input Path</td>\n",
       "      <td>C:\\Users\\pagoetz\\PycharmProjects\\ChronoTranscriber\\eval\\test_data\\input</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Output Path</td>\n",
       "      <td>C:\\Users\\pagoetz\\PycharmProjects\\ChronoTranscriber\\eval\\test_data\\output</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Ground Truth Path</td>\n",
       "      <td>C:\\Users\\pagoetz\\PycharmProjects\\ChronoTranscriber\\eval\\test_data\\ground_truth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Reports Path</td>\n",
       "      <td>C:\\Users\\pagoetz\\PycharmProjects\\ChronoTranscriber\\eval\\reports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Categories</td>\n",
       "      <td>address_books, bibliography, military_records</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Models</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:\\Users\\pagoetz\\PycharmProjects\\ChronoTranscriber\\eval\\reports\\latex_tables\\table_01_configuration.tex\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Load evaluation configuration\n",
    "# =============================================================================\n",
    "CONFIG_PATH = EVAL_DIR / \"eval_config.yaml\"\n",
    "\n",
    "with open(CONFIG_PATH, 'r', encoding='utf-8') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Extract paths\n",
    "INPUT_PATH = EVAL_DIR / config['dataset']['input_path']\n",
    "OUTPUT_PATH = EVAL_DIR / config['dataset']['output_path']\n",
    "GROUND_TRUTH_PATH = EVAL_DIR / config['dataset']['ground_truth_path']\n",
    "REPORTS_PATH = EVAL_DIR / config['evaluation']['reports_path']\n",
    "\n",
    "# Create reports directory\n",
    "REPORTS_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "# Extract categories and models\n",
    "CATEGORIES = [cat['name'] for cat in config['dataset']['categories']]\n",
    "MODELS = {m['name']: m for m in config['models']}\n",
    "\n",
    "# =============================================================================\n",
    "# Configuration Summary Table\n",
    "# =============================================================================\n",
    "config_data = {\n",
    "    'Parameter': ['Input Path', 'Output Path', 'Ground Truth Path', 'Reports Path',\n",
    "                  'Categories', 'Models'],\n",
    "    'Value': [str(INPUT_PATH), str(OUTPUT_PATH), str(GROUND_TRUTH_PATH), str(REPORTS_PATH),\n",
    "              ', '.join(CATEGORIES), str(len(MODELS))]\n",
    "}\n",
    "df_config = pd.DataFrame(config_data)\n",
    "\n",
    "display(HTML('<h4>Table 1: Evaluation Configuration</h4>'))\n",
    "display(HTML(df_config.to_html(index=False)))\n",
    "\n",
    "if SAVE_TABLES_LATEX:\n",
    "    latex_path = LATEX_OUTPUT_DIR / 'table_01_configuration.tex'\n",
    "    df_config.to_latex(latex_path, index=False,\n",
    "                       caption='Evaluation Configuration Parameters',\n",
    "                       label='tab:eval_config')\n",
    "    print(f'Saved: {latex_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Discover Available Data\n",
    "\n",
    "This section audits the evaluation data on disk to determine what can be evaluated in the current run.\n",
    "\n",
    "Using the configured paths, it:\n",
    "- Lists available **input sources** for each category.\n",
    "- Detects which **models have produced JSONL output** for each category.\n",
    "- Checks whether **ground truth JSONL files** exist for each category.\n",
    "\n",
    "**Why this matters**\n",
    "- The evaluation proceeds only for category–model combinations where both hypothesis output and ground truth exist.\n",
    "- This step makes missing artifacts explicit before running more expensive computations.\n",
    "\n",
    "**Output produced in this section**\n",
    "- A console summary for each category showing:\n",
    "  - Number of detected sources.\n",
    "  - Which models have JSONL output.\n",
    "  - Whether ground truth exists (and how many files)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T11:09:41.483832Z",
     "iopub.status.busy": "2026-02-27T11:09:41.483142Z",
     "iopub.status.idle": "2026-02-27T11:09:41.509856Z",
     "shell.execute_reply": "2026-02-27T11:09:41.508196Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "AVAILABLE DATA SUMMARY\n",
      "============================================================\n",
      "\n",
      "ADDRESS_BOOKS\n",
      "----------------------------------------\n",
      "  Input sources: 1\n",
      "    - address_books\n",
      "  Models with JSONL output: 7\n",
      "    - claude_haiku_4.5_medium\n",
      "    - claude_sonnet_4.5_medium\n",
      "    - gemini_3.0_flash\n",
      "    - gemini_3.0_pro_medium\n",
      "    - gpt_5.2_medium\n",
      "    - gpt_5_mini_medium\n",
      "    - tesseract\n",
      "  Ground truth JSONL: Yes (1 files)\n",
      "\n",
      "BIBLIOGRAPHY\n",
      "----------------------------------------\n",
      "  Input sources: 1\n",
      "    - Whitaker_1913_English_Cookery_Books_to_the_Year_1850.pdf\n",
      "  Models with JSONL output: 7\n",
      "    - claude_haiku_4.5_medium\n",
      "    - claude_sonnet_4.5_medium\n",
      "    - gemini_3.0_flash\n",
      "    - gemini_3.0_pro_medium\n",
      "    - gpt_5.2_medium\n",
      "    - gpt_5_mini_medium\n",
      "    - tesseract\n",
      "  Ground truth JSONL: Yes (1 files)\n",
      "\n",
      "MILITARY_RECORDS\n",
      "----------------------------------------\n",
      "  Input sources: 3\n",
      "    - Antonio Franco.pdf\n",
      "    - Carlos Schimidt.pdf\n",
      "    - Elza Elias.pdf\n",
      "  Models with JSONL output: 7\n",
      "    - claude_haiku_4.5_medium\n",
      "    - claude_sonnet_4.5_medium\n",
      "    - gemini_3.0_flash\n",
      "    - gemini_3.0_pro_medium\n",
      "    - gpt_5.2_medium\n",
      "    - gpt_5_mini_medium\n",
      "    - tesseract\n",
      "  Ground truth JSONL: Yes (3 files)\n"
     ]
    }
   ],
   "source": [
    "def discover_sources(category: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Discover source files/folders in the input directory for a category.\n",
    "    \n",
    "    Args:\n",
    "        category: Dataset category\n",
    "        \n",
    "    Returns:\n",
    "        List of source names\n",
    "    \"\"\"\n",
    "    input_dir = INPUT_PATH / category\n",
    "    \n",
    "    if not input_dir.exists():\n",
    "        return []\n",
    "    \n",
    "    sources = []\n",
    "    has_direct_images = False\n",
    "    \n",
    "    for item in input_dir.iterdir():\n",
    "        if item.is_file() and item.suffix.lower() == '.pdf':\n",
    "            sources.append(item.name)\n",
    "        elif item.is_file() and item.suffix.lower() in ['.jpg', '.jpeg', '.png', '.tiff']:\n",
    "            has_direct_images = True\n",
    "        elif item.is_dir():\n",
    "            # Check if folder contains images\n",
    "            images = list(item.glob('*.jpg')) + list(item.glob('*.png'))\n",
    "            if images:\n",
    "                sources.append(item.name)\n",
    "    \n",
    "    # If images are directly in the category folder (not in subfolders),\n",
    "    # treat the whole folder as a single source named after the category.\n",
    "    if has_direct_images and not sources:\n",
    "        sources.append(category)\n",
    "    \n",
    "    return sorted(sources)\n",
    "\n",
    "\n",
    "def discover_available_models(category: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Discover which models have JSONL output for a given category.\n",
    "    \n",
    "    Args:\n",
    "        category: Dataset category\n",
    "        \n",
    "    Returns:\n",
    "        List of model names with available output\n",
    "    \"\"\"\n",
    "    output_dir = OUTPUT_PATH / category\n",
    "    \n",
    "    if not output_dir.exists():\n",
    "        return []\n",
    "    \n",
    "    models = []\n",
    "    for d in output_dir.iterdir():\n",
    "        if d.is_dir():\n",
    "            # Check if model directory has any JSONL files\n",
    "            jsonl_files = list(d.rglob('*.jsonl'))\n",
    "            if jsonl_files:\n",
    "                models.append(d.name)\n",
    "    \n",
    "    return sorted(models)\n",
    "\n",
    "\n",
    "def check_ground_truth_available(category: str) -> Tuple[bool, int]:\n",
    "    \"\"\"\n",
    "    Check if ground truth JSONL files exist for a category.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (has_ground_truth, count_of_files)\n",
    "    \"\"\"\n",
    "    gt_dir = GROUND_TRUTH_PATH / category\n",
    "    if not gt_dir.exists():\n",
    "        return False, 0\n",
    "    \n",
    "    jsonl_files = list(gt_dir.glob('*.jsonl'))\n",
    "    return len(jsonl_files) > 0, len(jsonl_files)\n",
    "\n",
    "\n",
    "# Discover and display available data\n",
    "print(\"=\" * 60)\n",
    "print(\"AVAILABLE DATA SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "data_summary = {}\n",
    "\n",
    "for category in CATEGORIES:\n",
    "    sources = discover_sources(category)\n",
    "    available_models = discover_available_models(category)\n",
    "    gt_available, gt_count = check_ground_truth_available(category)\n",
    "    \n",
    "    data_summary[category] = {\n",
    "        'sources': sources,\n",
    "        'models': available_models,\n",
    "        'ground_truth_available': gt_available,\n",
    "        'ground_truth_count': gt_count,\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{category.upper()}\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"  Input sources: {len(sources)}\")\n",
    "    if sources:\n",
    "        for s in sources[:5]:\n",
    "            print(f\"    - {s}\")\n",
    "        if len(sources) > 5:\n",
    "            print(f\"    ... and {len(sources) - 5} more\")\n",
    "    print(f\"  Models with JSONL output: {len(available_models)}\")\n",
    "    for m in available_models:\n",
    "        print(f\"    - {m}\")\n",
    "    print(f\"  Ground truth JSONL: {'Yes' if gt_available else 'No'} ({gt_count} files)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Page-Level Evaluation\n",
    "\n",
    "This section defines the evaluation logic and computes accuracy metrics at the **page** level.\n",
    "\n",
    "### Unit of analysis\n",
    "The unit of analysis is a page transcription parsed from a JSONL file. Pages are aligned between:\n",
    "- **Reference**: ground truth JSONL\n",
    "- **Hypothesis**: model output JSONL\n",
    "\n",
    "A page is evaluated only if:\n",
    "- The ground-truth page exists and contains transcribable text, and\n",
    "- The model output page exists and contains transcribable text.\n",
    "\n",
    "Pages flagged as `no_transcribable_text` or `transcription_not_possible` are treated as non-evaluable.\n",
    "\n",
    "### What is computed\n",
    "For each aligned, evaluable page, the notebook calls .compute_metrics(...) to produce:\n",
    "- Overall CER and WER\n",
    "- Content-only CER and WER (formatting stripped)\n",
    "\n",
    "Page-level results are then aggregated with .aggregate_metrics(...) (micro-averaging by reference length).\n",
    "\n",
    "**Output produced in this section**\n",
    "- In-memory structures:\n",
    "  - `all_results`: nested results by category, model, source, and page.\n",
    "  - `aggregated_metrics`: summary metrics by category and model.\n",
    "- A console progress summary for each evaluated model/category showing:\n",
    "  - CER and WER\n",
    "  - Count of evaluated pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T11:09:41.514026Z",
     "iopub.status.busy": "2026-02-27T11:09:41.513798Z",
     "iopub.status.idle": "2026-02-27T11:09:41.528477Z",
     "shell.execute_reply": "2026-02-27T11:09:41.526789Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page-level evaluation functions defined.\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class PageEvaluationResult:\n",
    "    \"\"\"Container for per-page evaluation results.\"\"\"\n",
    "    page_index: int\n",
    "    image_name: str\n",
    "    metrics: Optional[TranscriptionMetrics]\n",
    "    ground_truth_found: bool\n",
    "    output_found: bool\n",
    "    error: Optional[str] = None\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class SourceEvaluationResult:\n",
    "    \"\"\"Container for source-level evaluation results.\"\"\"\n",
    "    category: str\n",
    "    model_name: str\n",
    "    source_name: str\n",
    "    page_results: List[PageEvaluationResult]\n",
    "    aggregated_metrics: Optional[TranscriptionMetrics]\n",
    "    ground_truth_found: bool\n",
    "    output_found: bool\n",
    "    error: Optional[str] = None\n",
    "    \n",
    "    @property\n",
    "    def total_pages(self) -> int:\n",
    "        return len(self.page_results)\n",
    "    \n",
    "    @property\n",
    "    def evaluated_pages(self) -> int:\n",
    "        return sum(1 for p in self.page_results if p.metrics is not None)\n",
    "\n",
    "\n",
    "def evaluate_source_pages(\n",
    "    category: str,\n",
    "    model_name: str,\n",
    "    source_name: str,\n",
    ") -> SourceEvaluationResult:\n",
    "    \"\"\"\n",
    "    Evaluate a source by comparing pages from model output to ground truth.\n",
    "    \n",
    "    Args:\n",
    "        category: Dataset category\n",
    "        model_name: Model identifier\n",
    "        source_name: Source file/folder name\n",
    "        \n",
    "    Returns:\n",
    "        SourceEvaluationResult with per-page and aggregated metrics\n",
    "    \"\"\"\n",
    "    # Load ground truth pages\n",
    "    gt_doc = load_ground_truth_pages(GROUND_TRUTH_PATH, category, source_name)\n",
    "    if gt_doc is None or not gt_doc.pages:\n",
    "        return SourceEvaluationResult(\n",
    "            category=category,\n",
    "            model_name=model_name,\n",
    "            source_name=source_name,\n",
    "            page_results=[],\n",
    "            aggregated_metrics=None,\n",
    "            ground_truth_found=False,\n",
    "            output_found=False,\n",
    "            error=\"Ground truth JSONL not found\",\n",
    "        )\n",
    "    \n",
    "    # Load model output pages\n",
    "    hyp_doc = load_page_transcriptions(OUTPUT_PATH, category, model_name, source_name)\n",
    "    if hyp_doc is None or not hyp_doc.pages:\n",
    "        return SourceEvaluationResult(\n",
    "            category=category,\n",
    "            model_name=model_name,\n",
    "            source_name=source_name,\n",
    "            page_results=[],\n",
    "            aggregated_metrics=None,\n",
    "            ground_truth_found=True,\n",
    "            output_found=False,\n",
    "            error=\"Model output JSONL not found\",\n",
    "        )\n",
    "    \n",
    "    # Align pages\n",
    "    aligned = align_pages(hyp_doc, gt_doc)\n",
    "    \n",
    "    # Compute per-page metrics\n",
    "    page_results: List[PageEvaluationResult] = []\n",
    "    valid_metrics: List[TranscriptionMetrics] = []\n",
    "    \n",
    "    for hyp_page, gt_page in aligned:\n",
    "        # Determine page info\n",
    "        if gt_page:\n",
    "            page_index = gt_page.page_index\n",
    "            image_name = gt_page.image_name or (hyp_page.image_name if hyp_page else \"\")\n",
    "        elif hyp_page:\n",
    "            page_index = hyp_page.page_index\n",
    "            image_name = hyp_page.image_name\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        # Check availability\n",
    "        gt_found = gt_page is not None and gt_page.has_text()\n",
    "        hyp_found = hyp_page is not None and hyp_page.has_text()\n",
    "        \n",
    "        if not gt_found:\n",
    "            page_results.append(PageEvaluationResult(\n",
    "                page_index=page_index,\n",
    "                image_name=image_name,\n",
    "                metrics=None,\n",
    "                ground_truth_found=False,\n",
    "                output_found=hyp_found,\n",
    "                error=\"No ground truth for page\",\n",
    "            ))\n",
    "            continue\n",
    "        \n",
    "        if not hyp_found:\n",
    "            page_results.append(PageEvaluationResult(\n",
    "                page_index=page_index,\n",
    "                image_name=image_name,\n",
    "                metrics=None,\n",
    "                ground_truth_found=True,\n",
    "                output_found=False,\n",
    "                error=\"No model output for page\",\n",
    "            ))\n",
    "            continue\n",
    "        \n",
    "        # Compute metrics\n",
    "        try:\n",
    "            metrics = compute_metrics(\n",
    "                gt_page.transcription,\n",
    "                hyp_page.transcription,\n",
    "                normalize=True,\n",
    "            )\n",
    "            page_results.append(PageEvaluationResult(\n",
    "                page_index=page_index,\n",
    "                image_name=image_name,\n",
    "                metrics=metrics,\n",
    "                ground_truth_found=True,\n",
    "                output_found=True,\n",
    "            ))\n",
    "            valid_metrics.append(metrics)\n",
    "        except Exception as e:\n",
    "            page_results.append(PageEvaluationResult(\n",
    "                page_index=page_index,\n",
    "                image_name=image_name,\n",
    "                metrics=None,\n",
    "                ground_truth_found=True,\n",
    "                output_found=True,\n",
    "                error=str(e),\n",
    "            ))\n",
    "    \n",
    "    # Aggregate metrics\n",
    "    aggregated = aggregate_metrics(valid_metrics) if valid_metrics else None\n",
    "    \n",
    "    return SourceEvaluationResult(\n",
    "        category=category,\n",
    "        model_name=model_name,\n",
    "        source_name=source_name,\n",
    "        page_results=page_results,\n",
    "        aggregated_metrics=aggregated,\n",
    "        ground_truth_found=True,\n",
    "        output_found=True,\n",
    "    )\n",
    "\n",
    "\n",
    "def evaluate_model_category(\n",
    "    category: str,\n",
    "    model_name: str,\n",
    ") -> Tuple[List[SourceEvaluationResult], Optional[TranscriptionMetrics]]:\n",
    "    \"\"\"\n",
    "    Evaluate all sources in a category for a given model.\n",
    "    \n",
    "    Args:\n",
    "        category: Dataset category\n",
    "        model_name: Model identifier\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (list of per-source results, aggregated metrics)\n",
    "    \"\"\"\n",
    "    sources = discover_sources(category)\n",
    "    results = []\n",
    "    all_page_metrics = []\n",
    "    \n",
    "    for source in sources:\n",
    "        result = evaluate_source_pages(category, model_name, source)\n",
    "        results.append(result)\n",
    "        \n",
    "        # Collect valid page metrics for aggregation\n",
    "        for page_result in result.page_results:\n",
    "            if page_result.metrics is not None:\n",
    "                all_page_metrics.append(page_result.metrics)\n",
    "    \n",
    "    aggregated = aggregate_metrics(all_page_metrics) if all_page_metrics else None\n",
    "    \n",
    "    return results, aggregated\n",
    "\n",
    "\n",
    "print(\"Page-level evaluation functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T11:09:41.533567Z",
     "iopub.status.busy": "2026-02-27T11:09:41.532772Z",
     "iopub.status.idle": "2026-02-27T11:19:42.350549Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RUNNING PAGE-LEVEL EVALUATION\n",
      "============================================================\n",
      "\n",
      "ADDRESS_BOOKS\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  claude_haiku_4.5_medium:\n",
      "    CER: 9.80%  |  WER: 38.66%\n",
      "    Pages evaluated: 31/31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  claude_sonnet_4.5_medium:\n",
      "    CER: 6.78%  |  WER: 23.36%\n",
      "    Pages evaluated: 31/31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  gemini_3.0_flash:\n",
      "    CER: 7.92%  |  WER: 24.29%\n",
      "    Pages evaluated: 31/31\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m40\u001b[39m)\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m model_name \u001b[38;5;129;01min\u001b[39;00m available_models:\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m     results, agg_metrics = \u001b[43mevaluate_model_category\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcategory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m     all_results[category][model_name] = results\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m agg_metrics:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 179\u001b[39m, in \u001b[36mevaluate_model_category\u001b[39m\u001b[34m(category, model_name)\u001b[39m\n\u001b[32m    176\u001b[39m all_page_metrics = []\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m source \u001b[38;5;129;01min\u001b[39;00m sources:\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m     result = \u001b[43mevaluate_source_pages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcategory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    180\u001b[39m     results.append(result)\n\u001b[32m    182\u001b[39m     \u001b[38;5;66;03m# Collect valid page metrics for aggregation\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 123\u001b[39m, in \u001b[36mevaluate_source_pages\u001b[39m\u001b[34m(category, model_name, source_name)\u001b[39m\n\u001b[32m    121\u001b[39m \u001b[38;5;66;03m# Compute metrics\u001b[39;00m\n\u001b[32m    122\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m     metrics = \u001b[43mcompute_metrics\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgt_page\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtranscription\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhyp_page\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtranscription\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    128\u001b[39m     page_results.append(PageEvaluationResult(\n\u001b[32m    129\u001b[39m         page_index=page_index,\n\u001b[32m    130\u001b[39m         image_name=image_name,\n\u001b[32m   (...)\u001b[39m\u001b[32m    133\u001b[39m         output_found=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    134\u001b[39m     ))\n\u001b[32m    135\u001b[39m     valid_metrics.append(metrics)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\PycharmProjects\\ChronoTranscriber\\eval\\metrics.py:473\u001b[39m, in \u001b[36mcompute_metrics\u001b[39m\u001b[34m(reference, hypothesis, normalize, compute_formatting)\u001b[39m\n\u001b[32m    470\u001b[39m ref_content = strip_formatting(reference)\n\u001b[32m    471\u001b[39m hyp_content = strip_formatting(hypothesis)\n\u001b[32m--> \u001b[39m\u001b[32m473\u001b[39m content_cer, content_char_dist, ref_content_chars, _ = \u001b[43mcompute_cer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[43m    \u001b[49m\u001b[43mref_content\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhyp_content\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\n\u001b[32m    475\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    476\u001b[39m content_wer, content_word_dist, ref_content_words, _ = compute_wer(\n\u001b[32m    477\u001b[39m     ref_content, hyp_content, normalize\n\u001b[32m    478\u001b[39m )\n\u001b[32m    480\u001b[39m \u001b[38;5;66;03m# Formatting-specific metrics\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\PycharmProjects\\ChronoTranscriber\\eval\\metrics.py:264\u001b[39m, in \u001b[36mcompute_cer\u001b[39m\u001b[34m(reference, hypothesis, normalize)\u001b[39m\n\u001b[32m    261\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[32m0.0\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m\n\u001b[32m    262\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mlen\u001b[39m(hyp_chars)), \u001b[38;5;28mlen\u001b[39m(hyp_chars), \u001b[32m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(hyp_chars)\n\u001b[32m--> \u001b[39m\u001b[32m264\u001b[39m distance = \u001b[43mlevenshtein_distance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mref_chars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhyp_chars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    265\u001b[39m cer = distance / \u001b[38;5;28mlen\u001b[39m(ref_chars)\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cer, distance, \u001b[38;5;28mlen\u001b[39m(ref_chars), \u001b[38;5;28mlen\u001b[39m(hyp_chars)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\PycharmProjects\\ChronoTranscriber\\eval\\metrics.py:179\u001b[39m, in \u001b[36mlevenshtein_distance\u001b[39m\u001b[34m(s1, s2)\u001b[39m\n\u001b[32m    165\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    166\u001b[39m \u001b[33;03mCompute the Levenshtein distance between two sequences.\u001b[39;00m\n\u001b[32m    167\u001b[39m \u001b[33;03m\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    176\u001b[39m \u001b[33;03m    required to transform s2 into s1.\u001b[39;00m\n\u001b[32m    177\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(s1) < \u001b[38;5;28mlen\u001b[39m(s2):\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlevenshtein_distance\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(s2) == \u001b[32m0\u001b[39m:\n\u001b[32m    182\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(s1)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\PycharmProjects\\ChronoTranscriber\\eval\\metrics.py:193\u001b[39m, in \u001b[36mlevenshtein_distance\u001b[39m\u001b[34m(s1, s2)\u001b[39m\n\u001b[32m    191\u001b[39m         deletions = current_row[j] + \u001b[32m1\u001b[39m\n\u001b[32m    192\u001b[39m         substitutions = previous_row[j] + (c1 != c2)\n\u001b[32m--> \u001b[39m\u001b[32m193\u001b[39m         current_row.append(\u001b[38;5;28mmin\u001b[39m(insertions, deletions, substitutions))\n\u001b[32m    194\u001b[39m     previous_row = current_row\n\u001b[32m    196\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m previous_row[-\u001b[32m1\u001b[39m]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Run full evaluation\n",
    "print(\"=\" * 60)\n",
    "print(\"RUNNING PAGE-LEVEL EVALUATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "all_results: Dict[str, Dict[str, List[SourceEvaluationResult]]] = {}\n",
    "aggregated_metrics: Dict[str, Dict[str, TranscriptionMetrics]] = {}\n",
    "\n",
    "for category in CATEGORIES:\n",
    "    all_results[category] = {}\n",
    "    aggregated_metrics[category] = {}\n",
    "    \n",
    "    available_models = discover_available_models(category)\n",
    "    gt_available, gt_count = check_ground_truth_available(category)\n",
    "    \n",
    "    if not available_models:\n",
    "        print(f\"\\n{category}: No model outputs found (skipping)\")\n",
    "        continue\n",
    "    \n",
    "    if not gt_available:\n",
    "        print(f\"\\n{category}: No ground truth JSONL files (skipping)\")\n",
    "        print(f\"  Hint: Run 'python main/prepare_ground_truth.py --extract' to create editable files\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n{category.upper()}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for model_name in available_models:\n",
    "        results, agg_metrics = evaluate_model_category(category, model_name)\n",
    "        all_results[category][model_name] = results\n",
    "        \n",
    "        if agg_metrics:\n",
    "            aggregated_metrics[category][model_name] = agg_metrics\n",
    "            total_pages = sum(r.total_pages for r in results)\n",
    "            eval_pages = sum(r.evaluated_pages for r in results)\n",
    "            print(f\"  {model_name}:\")\n",
    "            print(f\"    CER: {agg_metrics.cer*100:.2f}%  |  WER: {agg_metrics.wer*100:.2f}%\")\n",
    "            print(f\"    Pages evaluated: {eval_pages}/{total_pages}\")\n",
    "        else:\n",
    "            errors = [r.error for r in results if r.error]\n",
    "            print(f\"  {model_name}: No valid evaluations\")\n",
    "            if errors:\n",
    "                print(f\"    Error: {errors[0]}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EVALUATION COMPLETE\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Results Summary\n",
    "\n",
    "This section converts the evaluation results into publication-ready summary tables.\n",
    "\n",
    "### What is summarized\n",
    "- **By category**: performance for each model within each dataset category (`CATEGORIES`).\n",
    "- **Overall**: performance for each model aggregated across all categories.\n",
    "\n",
    "### Outputs produced\n",
    "- **Table 2**: Transcription accuracy by model and category (inline HTML; optional LaTeX export).\n",
    "- **Table 3**: Overall model ranking across categories (inline HTML; optional LaTeX export).\n",
    "\n",
    "If `SAVE_TABLES_LATEX = True`, the corresponding TeX table files are written to `LATEX_OUTPUT_DIR` using `DataFrame.to_latex(...)` with captions and labels suitable for manuscript inclusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T09:47:19.012249Z",
     "iopub.status.busy": "2026-02-21T09:47:19.011757Z",
     "iopub.status.idle": "2026-02-21T09:47:19.074641Z",
     "shell.execute_reply": "2026-02-21T09:47:19.072973Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Table 2: Pure Transcription Accuracy by Model and Category (structural markup stripped before comparison)</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Model</th>\n",
       "      <th>Category</th>\n",
       "      <th>CER (%)</th>\n",
       "      <th>WER (%)</th>\n",
       "      <th>Ref. Characters</th>\n",
       "      <th>Ref. Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>claude_haiku_4.5_medium</td>\n",
       "      <td>address_books</td>\n",
       "      <td>7.88</td>\n",
       "      <td>35.48</td>\n",
       "      <td>99,393</td>\n",
       "      <td>12,656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>claude_haiku_4.5_medium</td>\n",
       "      <td>bibliography</td>\n",
       "      <td>6.95</td>\n",
       "      <td>12.58</td>\n",
       "      <td>64,541</td>\n",
       "      <td>11,265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>claude_haiku_4.5_medium</td>\n",
       "      <td>military_records</td>\n",
       "      <td>34.65</td>\n",
       "      <td>63.82</td>\n",
       "      <td>2,892</td>\n",
       "      <td>398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>claude_sonnet_4.5_medium</td>\n",
       "      <td>address_books</td>\n",
       "      <td>5.28</td>\n",
       "      <td>20.27</td>\n",
       "      <td>99,393</td>\n",
       "      <td>12,656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>claude_sonnet_4.5_medium</td>\n",
       "      <td>bibliography</td>\n",
       "      <td>6.53</td>\n",
       "      <td>12.38</td>\n",
       "      <td>64,541</td>\n",
       "      <td>11,265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>claude_sonnet_4.5_medium</td>\n",
       "      <td>military_records</td>\n",
       "      <td>26.35</td>\n",
       "      <td>37.19</td>\n",
       "      <td>2,892</td>\n",
       "      <td>398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>gemini_3.0_flash</td>\n",
       "      <td>address_books</td>\n",
       "      <td>6.44</td>\n",
       "      <td>20.20</td>\n",
       "      <td>99,393</td>\n",
       "      <td>12,656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>gemini_3.0_flash</td>\n",
       "      <td>bibliography</td>\n",
       "      <td>6.30</td>\n",
       "      <td>10.58</td>\n",
       "      <td>64,541</td>\n",
       "      <td>11,265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>gemini_3.0_flash</td>\n",
       "      <td>military_records</td>\n",
       "      <td>38.11</td>\n",
       "      <td>50.00</td>\n",
       "      <td>2,892</td>\n",
       "      <td>398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>gemini_3.0_pro_medium</td>\n",
       "      <td>address_books</td>\n",
       "      <td>1.91</td>\n",
       "      <td>16.06</td>\n",
       "      <td>99,393</td>\n",
       "      <td>12,656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>gemini_3.0_pro_medium</td>\n",
       "      <td>bibliography</td>\n",
       "      <td>6.49</td>\n",
       "      <td>12.30</td>\n",
       "      <td>64,541</td>\n",
       "      <td>11,265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>gemini_3.0_pro_medium</td>\n",
       "      <td>military_records</td>\n",
       "      <td>86.20</td>\n",
       "      <td>102.76</td>\n",
       "      <td>2,892</td>\n",
       "      <td>398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>gpt_5.2_medium</td>\n",
       "      <td>address_books</td>\n",
       "      <td>5.47</td>\n",
       "      <td>28.99</td>\n",
       "      <td>99,393</td>\n",
       "      <td>12,656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>gpt_5.2_medium</td>\n",
       "      <td>bibliography</td>\n",
       "      <td>5.93</td>\n",
       "      <td>8.38</td>\n",
       "      <td>64,541</td>\n",
       "      <td>11,265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>gpt_5.2_medium</td>\n",
       "      <td>military_records</td>\n",
       "      <td>24.79</td>\n",
       "      <td>31.91</td>\n",
       "      <td>2,892</td>\n",
       "      <td>398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>gpt_5_mini_medium</td>\n",
       "      <td>address_books</td>\n",
       "      <td>5.70</td>\n",
       "      <td>33.61</td>\n",
       "      <td>99,393</td>\n",
       "      <td>12,656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>gpt_5_mini_medium</td>\n",
       "      <td>bibliography</td>\n",
       "      <td>41.46</td>\n",
       "      <td>45.51</td>\n",
       "      <td>64,541</td>\n",
       "      <td>11,265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>gpt_5_mini_medium</td>\n",
       "      <td>military_records</td>\n",
       "      <td>24.27</td>\n",
       "      <td>40.70</td>\n",
       "      <td>2,892</td>\n",
       "      <td>398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tesseract</td>\n",
       "      <td>address_books</td>\n",
       "      <td>87.89</td>\n",
       "      <td>145.17</td>\n",
       "      <td>99,393</td>\n",
       "      <td>12,656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tesseract</td>\n",
       "      <td>bibliography</td>\n",
       "      <td>9.43</td>\n",
       "      <td>18.71</td>\n",
       "      <td>64,541</td>\n",
       "      <td>11,265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tesseract</td>\n",
       "      <td>military_records</td>\n",
       "      <td>71.54</td>\n",
       "      <td>137.69</td>\n",
       "      <td>2,892</td>\n",
       "      <td>398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:\\Users\\pagoetz\\PycharmProjects\\ChronoTranscriber\\eval\\reports\\latex_tables\\table_02_cer_wer_by_category.tex\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>Table 3: Formatting Compliance by Model and Category (recall / ratio relative to ground truth)</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Model</th>\n",
       "      <th>Category</th>\n",
       "      <th>Page Tag Recall (%)</th>\n",
       "      <th>Heading Recall (%)</th>\n",
       "      <th>Bold/Italic Ratio (%)</th>\n",
       "      <th>GT Page Tags</th>\n",
       "      <th>GT Headings</th>\n",
       "      <th>GT Bold/Italic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>claude_haiku_4.5_medium</td>\n",
       "      <td>address_books</td>\n",
       "      <td>38.7</td>\n",
       "      <td>46.7</td>\n",
       "      <td>22.8</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>claude_haiku_4.5_medium</td>\n",
       "      <td>bibliography</td>\n",
       "      <td>76.7</td>\n",
       "      <td>11.4</td>\n",
       "      <td>31.0</td>\n",
       "      <td>30</td>\n",
       "      <td>35</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>claude_haiku_4.5_medium</td>\n",
       "      <td>military_records</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.7</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>claude_sonnet_4.5_medium</td>\n",
       "      <td>address_books</td>\n",
       "      <td>32.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>28.9</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>claude_sonnet_4.5_medium</td>\n",
       "      <td>bibliography</td>\n",
       "      <td>90.0</td>\n",
       "      <td>17.1</td>\n",
       "      <td>51.7</td>\n",
       "      <td>30</td>\n",
       "      <td>35</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>claude_sonnet_4.5_medium</td>\n",
       "      <td>military_records</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.7</td>\n",
       "      <td>2100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>gemini_3.0_flash</td>\n",
       "      <td>address_books</td>\n",
       "      <td>93.5</td>\n",
       "      <td>3.3</td>\n",
       "      <td>74.6</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>gemini_3.0_flash</td>\n",
       "      <td>bibliography</td>\n",
       "      <td>100.0</td>\n",
       "      <td>17.1</td>\n",
       "      <td>113.8</td>\n",
       "      <td>30</td>\n",
       "      <td>35</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>gemini_3.0_flash</td>\n",
       "      <td>military_records</td>\n",
       "      <td>300.0</td>\n",
       "      <td>66.7</td>\n",
       "      <td>3400.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>gemini_3.0_pro_medium</td>\n",
       "      <td>address_books</td>\n",
       "      <td>96.8</td>\n",
       "      <td>13.3</td>\n",
       "      <td>95.3</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>gemini_3.0_pro_medium</td>\n",
       "      <td>bibliography</td>\n",
       "      <td>93.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>63.8</td>\n",
       "      <td>30</td>\n",
       "      <td>35</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>gemini_3.0_pro_medium</td>\n",
       "      <td>military_records</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>gpt_5.2_medium</td>\n",
       "      <td>address_books</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>gpt_5.2_medium</td>\n",
       "      <td>bibliography</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>5.2</td>\n",
       "      <td>30</td>\n",
       "      <td>35</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>gpt_5.2_medium</td>\n",
       "      <td>military_records</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>gpt_5_mini_medium</td>\n",
       "      <td>address_books</td>\n",
       "      <td>22.6</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>gpt_5_mini_medium</td>\n",
       "      <td>bibliography</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.1</td>\n",
       "      <td>30</td>\n",
       "      <td>35</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>gpt_5_mini_medium</td>\n",
       "      <td>military_records</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tesseract</td>\n",
       "      <td>address_books</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.3</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tesseract</td>\n",
       "      <td>bibliography</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>30</td>\n",
       "      <td>35</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tesseract</td>\n",
       "      <td>military_records</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:\\Users\\pagoetz\\PycharmProjects\\ChronoTranscriber\\eval\\reports\\latex_tables\\table_03_formatting_compliance.tex\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 4. Results Summary\n",
    "# =============================================================================\n",
    "\n",
    "# Restructure for display: model -> category -> metrics\n",
    "model_category_metrics: Dict[str, Dict[str, TranscriptionMetrics]] = {}\n",
    "\n",
    "for category, models in aggregated_metrics.items():\n",
    "    for model_name, metrics in models.items():\n",
    "        if model_name not in model_category_metrics:\n",
    "            model_category_metrics[model_name] = {}\n",
    "        model_category_metrics[model_name][category] = metrics\n",
    "\n",
    "# =============================================================================\n",
    "# Table 2: Pure CER/WER (structural markup stripped from both ref and hyp)\n",
    "# =============================================================================\n",
    "if model_category_metrics:\n",
    "    cer_rows = []\n",
    "    for model_name in sorted(model_category_metrics.keys()):\n",
    "        for category in CATEGORIES:\n",
    "            if category in model_category_metrics[model_name]:\n",
    "                m = model_category_metrics[model_name][category]\n",
    "                cer_rows.append({\n",
    "                    'Model': model_name,\n",
    "                    'Category': category,\n",
    "                    'CER (%)': f'{m.content_cer*100:.2f}',\n",
    "                    'WER (%)': f'{m.content_wer*100:.2f}',\n",
    "                    'Ref. Characters': f'{m.ref_content_chars:,}',\n",
    "                    'Ref. Words': f'{m.ref_content_words:,}',\n",
    "                })\n",
    "\n",
    "    df_cer = pd.DataFrame(cer_rows)\n",
    "\n",
    "    display(HTML('<h4>Table 2: Pure Transcription Accuracy by Model and Category '\n",
    "                 '(structural markup stripped before comparison)</h4>'))\n",
    "    display(HTML(df_cer.to_html(index=False)))\n",
    "\n",
    "    if SAVE_TABLES_LATEX:\n",
    "        latex_path = LATEX_OUTPUT_DIR / 'table_02_cer_wer_by_category.tex'\n",
    "        df_cer.to_latex(latex_path, index=False,\n",
    "                        caption='Pure Transcription Accuracy (CER/WER) by Model and Document Category. '\n",
    "                                'All structural markup (page number tags, Markdown headings, bold/italic, '\n",
    "                                'footnote markers, image descriptions) stripped from both reference and '\n",
    "                                'hypothesis before comparison.',\n",
    "                        label='tab:cer_wer_by_category')\n",
    "        print(f'Saved: {latex_path}')\n",
    "\n",
    "    # ==========================================================================\n",
    "    # Table 3: Formatting Compliance by Model and Category\n",
    "    # ==========================================================================\n",
    "    fmt_rows = []\n",
    "    for model_name in sorted(model_category_metrics.keys()):\n",
    "        for category in CATEGORIES:\n",
    "            if category in model_category_metrics[model_name]:\n",
    "                m = model_category_metrics[model_name][category]\n",
    "                f = m.formatting\n",
    "                if f:\n",
    "                    pm_recall = (f.hyp_page_marker_pages / f.ref_page_marker_pages * 100\n",
    "                                 if f.ref_page_marker_pages > 0 else None)\n",
    "                    hd_recall = (f.hyp_heading_pages / f.ref_heading_pages * 100\n",
    "                                 if f.ref_heading_pages > 0 else None)\n",
    "                    bi_ratio  = (f.hyp_bold_italic_count / f.ref_bold_italic_count * 100\n",
    "                                 if f.ref_bold_italic_count > 0 else None)\n",
    "                    fmt_rows.append({\n",
    "                        'Model': model_name,\n",
    "                        'Category': category,\n",
    "                        'Page Tag Recall (%)': f'{pm_recall:.1f}' if pm_recall is not None else 'N/A',\n",
    "                        'Heading Recall (%)':  f'{hd_recall:.1f}' if hd_recall  is not None else 'N/A',\n",
    "                        'Bold/Italic Ratio (%)': f'{bi_ratio:.1f}' if bi_ratio   is not None else 'N/A',\n",
    "                        'GT Page Tags':    f.ref_page_marker_pages,\n",
    "                        'GT Headings':     f.ref_heading_pages,\n",
    "                        'GT Bold/Italic':  f.ref_bold_italic_count,\n",
    "                    })\n",
    "\n",
    "    if fmt_rows:\n",
    "        df_fmt = pd.DataFrame(fmt_rows)\n",
    "        display(HTML('<h4>Table 3: Formatting Compliance by Model and Category '\n",
    "                     '(recall / ratio relative to ground truth)</h4>'))\n",
    "        display(HTML(df_fmt.to_html(index=False)))\n",
    "\n",
    "        if SAVE_TABLES_LATEX:\n",
    "            latex_path = LATEX_OUTPUT_DIR / 'table_03_formatting_compliance.tex'\n",
    "            df_fmt.to_latex(latex_path, index=False,\n",
    "                            caption='Formatting Compliance by Model and Document Category. '\n",
    "                                    'Page Tag Recall: pages where model produced a \\\\texttt{<page\\\\_number>} tag '\n",
    "                                    'relative to ground truth pages with such tags. '\n",
    "                                    'Heading Recall: analogous for Markdown headings. '\n",
    "                                    'Bold/Italic Ratio: model bold+italic element count relative to ground truth.',\n",
    "                            label='tab:formatting_compliance')\n",
    "            print(f'Saved: {latex_path}')\n",
    "else:\n",
    "    print(\"\\nNo evaluation results available.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T09:47:19.080270Z",
     "iopub.status.busy": "2026-02-21T09:47:19.079826Z",
     "iopub.status.idle": "2026-02-21T09:47:19.111235Z",
     "shell.execute_reply": "2026-02-21T09:47:19.109505Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Table 4: Overall Model Rankings — Pure CER/WER (All Categories Combined)</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Rank</th>\n",
       "      <th>Model</th>\n",
       "      <th>CER (%)</th>\n",
       "      <th>WER (%)</th>\n",
       "      <th>Page Tag Recall (%)</th>\n",
       "      <th>Heading Recall (%)</th>\n",
       "      <th>Ref. Characters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>gemini_3.0_pro_medium</td>\n",
       "      <td>5.15</td>\n",
       "      <td>15.74</td>\n",
       "      <td>93.5</td>\n",
       "      <td>13.2</td>\n",
       "      <td>166,826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>gpt_5.2_medium</td>\n",
       "      <td>5.98</td>\n",
       "      <td>19.49</td>\n",
       "      <td>51.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>166,826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>claude_sonnet_4.5_medium</td>\n",
       "      <td>6.13</td>\n",
       "      <td>16.90</td>\n",
       "      <td>61.3</td>\n",
       "      <td>13.2</td>\n",
       "      <td>166,826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>gemini_3.0_flash</td>\n",
       "      <td>6.93</td>\n",
       "      <td>16.23</td>\n",
       "      <td>100.0</td>\n",
       "      <td>13.2</td>\n",
       "      <td>166,826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>claude_haiku_4.5_medium</td>\n",
       "      <td>7.98</td>\n",
       "      <td>25.33</td>\n",
       "      <td>56.5</td>\n",
       "      <td>29.4</td>\n",
       "      <td>166,826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>gpt_5_mini_medium</td>\n",
       "      <td>19.86</td>\n",
       "      <td>39.24</td>\n",
       "      <td>41.9</td>\n",
       "      <td>13.2</td>\n",
       "      <td>166,826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>tesseract</td>\n",
       "      <td>57.25</td>\n",
       "      <td>86.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>166,826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:\\Users\\pagoetz\\PycharmProjects\\ChronoTranscriber\\eval\\reports\\latex_tables\\table_04_overall_rankings.tex\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Overall Model Performance (All Categories Combined)\n",
    "# =============================================================================\n",
    "\n",
    "overall_model_metrics = {}\n",
    "\n",
    "for model_name, cat_metrics in model_category_metrics.items():\n",
    "    all_metrics = list(cat_metrics.values())\n",
    "    if all_metrics:\n",
    "        overall = aggregate_metrics(all_metrics)\n",
    "        overall_model_metrics[model_name] = overall\n",
    "\n",
    "# Build ranking DataFrame (ranked by pure CER)\n",
    "if overall_model_metrics:\n",
    "    ranked = sorted(overall_model_metrics.items(), key=lambda x: x[1].content_cer)\n",
    "\n",
    "    ranking_rows = []\n",
    "    for rank, (model_name, metrics) in enumerate(ranked, 1):\n",
    "        f = metrics.formatting\n",
    "        pm_recall = (f.hyp_page_marker_pages / f.ref_page_marker_pages * 100\n",
    "                     if f and f.ref_page_marker_pages > 0 else None)\n",
    "        hd_recall = (f.hyp_heading_pages / f.ref_heading_pages * 100\n",
    "                     if f and f.ref_heading_pages > 0 else None)\n",
    "        ranking_rows.append({\n",
    "            'Rank': rank,\n",
    "            'Model': model_name,\n",
    "            'CER (%)': f'{metrics.content_cer*100:.2f}',\n",
    "            'WER (%)': f'{metrics.content_wer*100:.2f}',\n",
    "            'Page Tag Recall (%)':  f'{pm_recall:.1f}' if pm_recall is not None else 'N/A',\n",
    "            'Heading Recall (%)':   f'{hd_recall:.1f}' if hd_recall  is not None else 'N/A',\n",
    "            'Ref. Characters': f'{metrics.ref_content_chars:,}',\n",
    "        })\n",
    "\n",
    "    df_ranking = pd.DataFrame(ranking_rows)\n",
    "\n",
    "    display(HTML('<h4>Table 4: Overall Model Rankings — Pure CER/WER (All Categories Combined)</h4>'))\n",
    "    display(HTML(df_ranking.to_html(index=False)))\n",
    "\n",
    "    if SAVE_TABLES_LATEX:\n",
    "        latex_path = LATEX_OUTPUT_DIR / 'table_04_overall_rankings.tex'\n",
    "        df_ranking.to_latex(latex_path, index=False,\n",
    "                            caption='Overall Model Rankings by Pure Character Error Rate '\n",
    "                                    '(all categories combined, structural markup stripped).',\n",
    "                            label='tab:overall_rankings')\n",
    "        print(f'Saved: {latex_path}')\n",
    "else:\n",
    "    print(\"No overall metrics available yet.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Detailed Per-Page Results\n",
    "\n",
    "This section supports qualitative inspection by drilling down from aggregate metrics to individual pages.\n",
    "\n",
    "### How to use this section\n",
    "The code cell below is parameterized by:\n",
    "- `SHOW_CATEGORY`: which dataset category to inspect.\n",
    "- `SHOW_MODEL`: which model to inspect (or `None` to use the first available).\n",
    "- `SHOW_SOURCE`: which source document to inspect (or `None` to use the first available).\n",
    "\n",
    "### Output produced\n",
    "- **Table 4**: Per-page CER/WER (and status codes for missing or unevaluable pages) for the selected model/source.\n",
    "- Optional: a TeX export of the same per-page table to `LATEX_OUTPUT_DIR`.\n",
    "\n",
    "This table is intended primarily for:\n",
    "- Diagnosing systematic failure modes (layout, scripts, tables, degraded scans).\n",
    "- Identifying outlier pages that dominate aggregate error rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T09:47:19.115508Z",
     "iopub.status.busy": "2026-02-21T09:47:19.115061Z",
     "iopub.status.idle": "2026-02-21T09:47:19.152872Z",
     "shell.execute_reply": "2026-02-21T09:47:19.150820Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed Page-Level Results: ADDRESS_BOOKS\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>Table 4: Per-Page Results - claude_haiku_4.5_medium / address_books</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Page</th>\n",
       "      <th>Image</th>\n",
       "      <th>CER (%)</th>\n",
       "      <th>WER (%)</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>STA_H_43_46_0010_pre_processed.jpg</td>\n",
       "      <td>8.43</td>\n",
       "      <td>34.10</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>STA_H_43_46_0011_pre_processed.jpg</td>\n",
       "      <td>9.77</td>\n",
       "      <td>37.56</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>STA_H_43_46_0012_pre_processed.jpg</td>\n",
       "      <td>9.66</td>\n",
       "      <td>36.83</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>STA_H_43_46_0013_pre_processed.jpg</td>\n",
       "      <td>10.86</td>\n",
       "      <td>42.72</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>STA_H_43_46_0014_pre_processed.jpg</td>\n",
       "      <td>12.44</td>\n",
       "      <td>45.06</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>STA_H_43_46_0015_pre_processed.jpg</td>\n",
       "      <td>10.55</td>\n",
       "      <td>40.47</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>STA_H_43_46_0016_pre_processed.jpg</td>\n",
       "      <td>13.07</td>\n",
       "      <td>46.79</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>STA_H_43_46_0017_pre_processed.jpg</td>\n",
       "      <td>7.84</td>\n",
       "      <td>37.56</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>STA_H_43_46_0018_pre_processed.jpg</td>\n",
       "      <td>8.98</td>\n",
       "      <td>36.97</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>STA_H_43_46_0019_pre_processed.jpg</td>\n",
       "      <td>8.13</td>\n",
       "      <td>34.24</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>STA_H_43_46_0020_pre_processed.jpg</td>\n",
       "      <td>10.85</td>\n",
       "      <td>37.47</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>STA_H_43_46_0021_pre_processed.jpg</td>\n",
       "      <td>9.14</td>\n",
       "      <td>32.75</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>STA_H_43_46_0022_pre_processed.jpg</td>\n",
       "      <td>11.22</td>\n",
       "      <td>33.25</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>STA_H_43_46_0023_pre_processed.jpg</td>\n",
       "      <td>7.59</td>\n",
       "      <td>30.14</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>STA_H_43_46_0024_pre_processed.jpg</td>\n",
       "      <td>9.06</td>\n",
       "      <td>36.08</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>STA_H_43_46_0025_pre_processed.jpg</td>\n",
       "      <td>8.65</td>\n",
       "      <td>32.62</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>STA_H_43_46_0026_pre_processed.jpg</td>\n",
       "      <td>10.35</td>\n",
       "      <td>43.27</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>STA_H_43_46_0027_pre_processed.jpg</td>\n",
       "      <td>9.05</td>\n",
       "      <td>35.96</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>STA_H_43_46_0028_pre_processed.jpg</td>\n",
       "      <td>8.78</td>\n",
       "      <td>34.67</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>STA_H_43_46_0029_pre_processed.jpg</td>\n",
       "      <td>12.53</td>\n",
       "      <td>53.54</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>STA_H_43_46_0030_pre_processed.jpg</td>\n",
       "      <td>12.55</td>\n",
       "      <td>51.93</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>STA_H_43_46_0031_pre_processed.jpg</td>\n",
       "      <td>9.22</td>\n",
       "      <td>36.36</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>STA_H_43_46_0032_pre_processed.jpg</td>\n",
       "      <td>11.68</td>\n",
       "      <td>39.57</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>STA_H_43_46_0033_pre_processed.jpg</td>\n",
       "      <td>7.70</td>\n",
       "      <td>33.79</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>STA_H_43_46_0034_pre_processed.jpg</td>\n",
       "      <td>10.36</td>\n",
       "      <td>37.64</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>STA_H_43_46_0035_pre_processed.jpg</td>\n",
       "      <td>9.01</td>\n",
       "      <td>40.60</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>STA_H_43_46_0036_pre_processed.jpg</td>\n",
       "      <td>11.10</td>\n",
       "      <td>53.24</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>STA_H_43_46_0037_pre_processed.jpg</td>\n",
       "      <td>7.60</td>\n",
       "      <td>35.32</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>STA_H_43_46_0038_pre_processed.jpg</td>\n",
       "      <td>9.54</td>\n",
       "      <td>41.24</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>STA_H_43_46_0039_pre_processed.jpg</td>\n",
       "      <td>7.23</td>\n",
       "      <td>35.04</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>STA_H_43_46_0040_pre_processed.jpg</td>\n",
       "      <td>9.94</td>\n",
       "      <td>32.92</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TOTAL</td>\n",
       "      <td></td>\n",
       "      <td>9.79</td>\n",
       "      <td>38.71</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:\\Users\\pagoetz\\PycharmProjects\\ChronoTranscriber\\eval\\reports\\latex_tables\\table_04_pages_claude_haiku_4_5_medium_address_books.tex\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 5. Detailed Per-Page Results\n",
    "# =============================================================================\n",
    "\n",
    "# Configurable: select category/model/source to display\n",
    "SHOW_CATEGORY = \"address_books\"  # Change as needed\n",
    "SHOW_MODEL = None  # Set to specific model name or None for first available\n",
    "SHOW_SOURCE = None  # Set to specific source name or None for first available\n",
    "\n",
    "if SHOW_CATEGORY in all_results and all_results[SHOW_CATEGORY]:\n",
    "    print(f\"Detailed Page-Level Results: {SHOW_CATEGORY.upper()}\")\n",
    "\n",
    "    models_to_show = [SHOW_MODEL] if SHOW_MODEL else list(all_results[SHOW_CATEGORY].keys())[:1]\n",
    "\n",
    "    for model_name in models_to_show:\n",
    "        if model_name not in all_results[SHOW_CATEGORY]:\n",
    "            continue\n",
    "\n",
    "        results = all_results[SHOW_CATEGORY][model_name]\n",
    "        sources_to_show = [r for r in results if r.source_name == SHOW_SOURCE] if SHOW_SOURCE else results[:1]\n",
    "\n",
    "        for source_result in sources_to_show:\n",
    "            # Build per-page DataFrame\n",
    "            page_rows = []\n",
    "            for page_result in source_result.page_results:\n",
    "                page_num = page_result.page_index + 1\n",
    "                img_name = page_result.image_name[:40] + '...' if len(page_result.image_name) > 40 else page_result.image_name\n",
    "\n",
    "                if page_result.metrics:\n",
    "                    page_rows.append({\n",
    "                        'Page': page_num,\n",
    "                        'Image': img_name,\n",
    "                        'CER (%)': f'{page_result.metrics.cer*100:.2f}',\n",
    "                        'WER (%)': f'{page_result.metrics.wer*100:.2f}',\n",
    "                        'Status': 'OK',\n",
    "                    })\n",
    "                else:\n",
    "                    page_rows.append({\n",
    "                        'Page': page_num,\n",
    "                        'Image': img_name,\n",
    "                        'CER (%)': '--',\n",
    "                        'WER (%)': '--',\n",
    "                        'Status': page_result.error or 'Error',\n",
    "                    })\n",
    "\n",
    "            # Add totals row if aggregated metrics exist\n",
    "            if source_result.aggregated_metrics:\n",
    "                m = source_result.aggregated_metrics\n",
    "                page_rows.append({\n",
    "                    'Page': 'TOTAL',\n",
    "                    'Image': '',\n",
    "                    'CER (%)': f'{m.cer*100:.2f}',\n",
    "                    'WER (%)': f'{m.wer*100:.2f}',\n",
    "                    'Status': '',\n",
    "                })\n",
    "\n",
    "            df_pages = pd.DataFrame(page_rows)\n",
    "\n",
    "            display(HTML(f'<h4>Table 4: Per-Page Results - {model_name} / {source_result.source_name}</h4>'))\n",
    "            display(HTML(df_pages.to_html(index=False)))\n",
    "\n",
    "            if SAVE_TABLES_LATEX:\n",
    "                # Sanitize filename\n",
    "                safe_model = model_name.replace('.', '_').replace(' ', '_')\n",
    "                safe_source = source_result.source_name.replace('.', '_').replace(' ', '_')[:30]\n",
    "                latex_path = LATEX_OUTPUT_DIR / f'table_04_pages_{safe_model}_{safe_source}.tex'\n",
    "                df_pages.to_latex(latex_path, index=False,\n",
    "                                  caption=f'Per-Page Transcription Results: {model_name}, {source_result.source_name}',\n",
    "                                  label=f'tab:pages_{safe_model}_{safe_source}')\n",
    "                print(f'Saved: {latex_path}')\n",
    "else:\n",
    "    print(f\"Category '{SHOW_CATEGORY}' not found in results or has no evaluated models.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Export Results\n",
    "\n",
    "This section exports evaluation outputs to disk for reproducibility, archiving, and downstream analysis.\n",
    "\n",
    "### Files written\n",
    "- A timestamped JSON report containing structured metrics suitable for programmatic reuse.\n",
    "- A timestamped CSV file containing a row per page-level result for spreadsheet workflows.\n",
    "- A timestamped Markdown report containing a human-readable summary (including a Markdown-formatted table).\n",
    "\n",
    "### Output produced\n",
    "- **Table 5**: Export summary (paths and record counts), rendered inline as HTML.\n",
    "- Optional: a TeX export of the export summary table saved to `LATEX_OUTPUT_DIR`.\n",
    "\n",
    "All export paths are anchored to `REPORTS_PATH` (for JSON/CSV/Markdown) and `LATEX_OUTPUT_DIR` (for LaTeX artifacts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T09:47:19.157598Z",
     "iopub.status.busy": "2026-02-21T09:47:19.156998Z",
     "iopub.status.idle": "2026-02-21T09:47:19.246679Z",
     "shell.execute_reply": "2026-02-21T09:47:19.244764Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON report saved: C:\\Users\\pagoetz\\PycharmProjects\\ChronoTranscriber\\eval\\reports\\eval_results_20260221_104719.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV report saved: C:\\Users\\pagoetz\\PycharmProjects\\ChronoTranscriber\\eval\\reports\\eval_results_20260221_104719.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>Table 5: Export Summary</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Export Type</th>\n",
       "      <th>File Path</th>\n",
       "      <th>Records</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>JSON Report</td>\n",
       "      <td>C:\\Users\\pagoetz\\PycharmProjects\\ChronoTranscriber\\eval\\reports\\eval_results_20260221_104719.json</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>CSV (Per-Page)</td>\n",
       "      <td>C:\\Users\\pagoetz\\PycharmProjects\\ChronoTranscriber\\eval\\reports\\eval_results_20260221_104719.csv</td>\n",
       "      <td>1582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LaTeX Tables</td>\n",
       "      <td>C:\\Users\\pagoetz\\PycharmProjects\\ChronoTranscriber\\eval\\reports\\latex_tables</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:\\Users\\pagoetz\\PycharmProjects\\ChronoTranscriber\\eval\\reports\\latex_tables\\table_05_export_summary.tex\n",
      "Markdown report saved: C:\\Users\\pagoetz\\PycharmProjects\\ChronoTranscriber\\eval\\reports\\eval_results_20260221_104719.md\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 6. Export Results\n",
    "# =============================================================================\n",
    "import csv\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# =============================================================================\n",
    "# Export aggregated metrics to JSON\n",
    "# =============================================================================\n",
    "json_report = {\n",
    "    \"timestamp\": timestamp,\n",
    "    \"evaluation_method\": \"page_level_jsonl\",\n",
    "    \"categories\": CATEGORIES,\n",
    "    \"models\": list(MODELS.keys()),\n",
    "    \"results\": {},\n",
    "}\n",
    "\n",
    "for model_name, cat_metrics in model_category_metrics.items():\n",
    "    json_report[\"results\"][model_name] = {\n",
    "        \"per_category\": {cat: m.to_dict() for cat, m in cat_metrics.items()},\n",
    "    }\n",
    "    if model_name in overall_model_metrics:\n",
    "        json_report[\"results\"][model_name][\"overall\"] = overall_model_metrics[model_name].to_dict()\n",
    "\n",
    "json_path = REPORTS_PATH / f\"eval_results_{timestamp}.json\"\n",
    "with open(json_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(json_report, f, indent=2)\n",
    "print(f\"JSON report saved: {json_path}\")\n",
    "\n",
    "# =============================================================================\n",
    "# Export to CSV (per-page, pure CER/WER + formatting flags)\n",
    "# =============================================================================\n",
    "csv_rows = []\n",
    "for category, models in all_results.items():\n",
    "    for model_name, sources in models.items():\n",
    "        for source_result in sources:\n",
    "            for page_result in source_result.page_results:\n",
    "                if page_result.metrics:\n",
    "                    m = page_result.metrics\n",
    "                    f = m.formatting\n",
    "                    csv_rows.append({\n",
    "                        'Model': model_name,\n",
    "                        'Category': category,\n",
    "                        'Source': source_result.source_name,\n",
    "                        'Page': page_result.page_index + 1,\n",
    "                        'Image': page_result.image_name,\n",
    "                        'CER (%)': round(m.content_cer * 100, 2),\n",
    "                        'WER (%)': round(m.content_wer * 100, 2),\n",
    "                        'Ref Chars': m.ref_content_chars,\n",
    "                        'PageTag_GT': f.ref_page_marker_pages if f else '',\n",
    "                        'PageTag_Hyp': f.hyp_page_marker_pages if f else '',\n",
    "                        'Heading_GT': f.ref_heading_pages if f else '',\n",
    "                        'Heading_Hyp': f.hyp_heading_pages if f else '',\n",
    "                        'BoldItalic_GT': f.ref_bold_italic_count if f else '',\n",
    "                        'BoldItalic_Hyp': f.hyp_bold_italic_count if f else '',\n",
    "                        'Status': 'OK',\n",
    "                    })\n",
    "                else:\n",
    "                    csv_rows.append({\n",
    "                        'Model': model_name,\n",
    "                        'Category': category,\n",
    "                        'Source': source_result.source_name,\n",
    "                        'Page': page_result.page_index + 1,\n",
    "                        'Image': page_result.image_name,\n",
    "                        'CER (%)': '',\n",
    "                        'WER (%)': '',\n",
    "                        'Ref Chars': '',\n",
    "                        'PageTag_GT': '', 'PageTag_Hyp': '',\n",
    "                        'Heading_GT': '', 'Heading_Hyp': '',\n",
    "                        'BoldItalic_GT': '', 'BoldItalic_Hyp': '',\n",
    "                        'Status': page_result.error or 'Error',\n",
    "                    })\n",
    "\n",
    "df_csv = pd.DataFrame(csv_rows)\n",
    "csv_path = REPORTS_PATH / f\"eval_results_{timestamp}.csv\"\n",
    "df_csv.to_csv(csv_path, index=False)\n",
    "print(f\"CSV report saved: {csv_path}\")\n",
    "\n",
    "# Display export summary\n",
    "display(HTML('<h4>Table 5: Export Summary</h4>'))\n",
    "export_summary = pd.DataFrame({\n",
    "    'Export Type': ['JSON Report', 'CSV (Per-Page)', 'LaTeX Tables'],\n",
    "    'File Path': [str(json_path), str(csv_path),\n",
    "                  str(LATEX_OUTPUT_DIR) if SAVE_TABLES_LATEX else 'Disabled'],\n",
    "    'Records': [len(json_report['results']), len(csv_rows),\n",
    "                len(list(LATEX_OUTPUT_DIR.glob('*.tex'))) if SAVE_TABLES_LATEX else 0],\n",
    "})\n",
    "display(HTML(export_summary.to_html(index=False)))\n",
    "\n",
    "if SAVE_TABLES_LATEX:\n",
    "    latex_path = LATEX_OUTPUT_DIR / 'table_05_export_summary.tex'\n",
    "    export_summary.to_latex(latex_path, index=False,\n",
    "                            caption='Summary of Exported Evaluation Results',\n",
    "                            label='tab:export_summary')\n",
    "    print(f'Saved: {latex_path}')\n",
    "\n",
    "# =============================================================================\n",
    "# Export Markdown summary\n",
    "# =============================================================================\n",
    "md_path = REPORTS_PATH / f\"eval_results_{timestamp}.md\"\n",
    "with open(md_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(f\"# ChronoTranscriber Evaluation Results\\n\\n\")\n",
    "    f.write(f\"**Generated:** {timestamp}\\n\\n\")\n",
    "    f.write(f\"**Evaluation Method:** Page-level JSONL comparison — \"\n",
    "            f\"CER/WER computed after stripping all structural markup\\n\\n\")\n",
    "    f.write(f\"## Models Evaluated\\n\\n\")\n",
    "    for name, info in MODELS.items():\n",
    "        f.write(f\"- **{name}**: {info.get('description', '')}\\n\")\n",
    "    f.write(f\"\\n## Results by Category\\n\\n\")\n",
    "    f.write(format_metrics_table(model_category_metrics, CATEGORIES, include_formatting=True))\n",
    "    f.write(f\"\\n\\n## Overall Rankings (Pure CER)\\n\\n\")\n",
    "    if overall_model_metrics:\n",
    "        ranked = sorted(overall_model_metrics.items(), key=lambda x: x[1].content_cer)\n",
    "        f.write(\"| Rank | Model | CER (%) | WER (%) |\\n\")\n",
    "        f.write(\"|------|-------|---------|--------|\\n\")\n",
    "        for rank, (model_name, metrics) in enumerate(ranked, 1):\n",
    "            f.write(f\"| {rank} | {model_name} | \"\n",
    "                    f\"{metrics.content_cer*100:.2f} | {metrics.content_wer*100:.2f} |\\n\")\n",
    "\n",
    "print(f\"Markdown report saved: {md_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 6b. API Cost Reference Table\n\nThis section reports published API pricing (as of February 2026) and computes per-page cost estimates from **actual token usage** recorded in the JSONL output files, not from assumed averages. For each model, every JSONL record is read and `raw_response.usage.input_tokens` / `raw_response.usage.output_tokens` are extracted and aggregated across all pages, categories, and sources. The mean input and output tokens per page are then used to compute the API cost at standard and batch rates.\n\nTesseract OCR is open-source and incurs no API cost. Transkribus costs are credit-based and included for comparison. All LLM providers offer a 50\\% discount on batch-processed requests. Output token counts for models run at medium reasoning budget include reasoning/thinking tokens, which are billed at the same rate as regular output tokens."
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b_cost_precise",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Token aggregates by model:\n  Model                           Pages  Mean In/Page  Mean Out/Page\n----------------------------------------------------------------------\n  GPT-5.2                            77          2989           2316\n  GPT-5 Mini                         82          2550           3047\n  Gemini 3 Pro Preview               77          2173           7076\n  Gemini 3 Flash Preview             77          2173           6348\n  Claude Sonnet 4.5                  77          3541           1840\n  Claude Haiku 4.5                   77          3541           2315\n  Tesseract OCR                       —             —              —\nSaved: C:\\Users\\pagoetz\\PycharmProjects\\ChronoTranscriber\\eval\\reports\\latex_tables\\table_06_cost_reference.tex\n\nCost comparison — estimated (2,000 in / 700 out) vs. actual:\n  Model                      Est. $/pg (std)  Act. $/pg (std)   Ratio\n----------------------------------------------------------------------\n  GPT-5.2                            0.01330          0.03765     2.8x\n  GPT-5 Mini                         0.00190          0.00673     3.5x\n  Gemini 3 Pro Preview               0.01240          0.08926     7.2x\n  Gemini 3 Flash Preview             0.00310          0.02013     6.5x\n  Claude Sonnet 4.5                  0.01650          0.03822     2.3x\n  Claude Haiku 4.5                   0.00550          0.01511     2.7x\n  Tesseract OCR                      0.00000          0.00000     nanx\n"
    },
    {
     "output_type": "display_data",
     "metadata": {},
     "data": {
      "text/html": [
       "<h4>Table 6: API Cost Reference — Token Pricing and Actual Per-Page Cost</h4><p><em>Per-page costs computed from actual token usage recorded in the JSONL output files. Output token counts for reasoning-enabled models (GPT-5.2, GPT-5 Mini, Gemini 3 Pro Preview, Claude Sonnet 4.5, Claude Haiku 4.5 — all run at medium reasoning budget) include reasoning/thinking tokens billed at the standard output rate. All LLM providers offer a 50% batch-processing discount. Transkribus estimate: 0.5 credits per printed page at ~€0.06/credit (add-on package), converted at USD/EUR ≈ 1.10; Metagrapho API applies a further 50% credit reduction. Prices as of February 2026.</em></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     }
    },
    {
     "output_type": "display_data",
     "metadata": {},
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>Model</th>\n      <th>Provider</th>\n      <th>Input ($/M tok)</th>\n      <th>Output ($/M tok)</th>\n      <th>Avg Input Tok/Page</th>\n      <th>Avg Output Tok/Page</th>\n      <th>$/page (standard)</th>\n      <th>$/page (batch 50%)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>GPT-5.2</td>\n      <td>OpenAI</td>\n      <td>1.75</td>\n      <td>14.00</td>\n      <td>2989</td>\n      <td>2316</td>\n      <td>0.03765</td>\n      <td>0.01883</td>\n    </tr>\n    <tr>\n      <td>GPT-5 Mini</td>\n      <td>OpenAI</td>\n      <td>0.25</td>\n      <td>2.00</td>\n      <td>2550</td>\n      <td>3047</td>\n      <td>0.00673</td>\n      <td>0.00337</td>\n    </tr>\n    <tr>\n      <td>Gemini 3 Pro Preview</td>\n      <td>Google</td>\n      <td>2.00</td>\n      <td>12.00</td>\n      <td>2173</td>\n      <td>7076</td>\n      <td>0.08926</td>\n      <td>0.04463</td>\n    </tr>\n    <tr>\n      <td>Gemini 3 Flash Preview</td>\n      <td>Google</td>\n      <td>0.50</td>\n      <td>3.00</td>\n      <td>2173</td>\n      <td>6348</td>\n      <td>0.02013</td>\n      <td>0.01007</td>\n    </tr>\n    <tr>\n      <td>Claude Sonnet 4.5</td>\n      <td>Anthropic</td>\n      <td>3.00</td>\n      <td>15.00</td>\n      <td>3541</td>\n      <td>1840</td>\n      <td>0.03822</td>\n      <td>0.01911</td>\n    </tr>\n    <tr>\n      <td>Claude Haiku 4.5</td>\n      <td>Anthropic</td>\n      <td>1.00</td>\n      <td>5.00</td>\n      <td>3541</td>\n      <td>2315</td>\n      <td>0.01511</td>\n      <td>0.00756</td>\n    </tr>\n    <tr>\n      <td>Tesseract OCR</td>\n      <td>Open-source</td>\n      <td>—</td>\n      <td>—</td>\n      <td>—</td>\n      <td>—</td>\n      <td>0 (free)</td>\n      <td>0 (free)</td>\n    </tr>\n    <tr>\n      <td>Transkribus (printed)</td>\n      <td>Transkribus</td>\n      <td>N/A (credit-based)</td>\n      <td>N/A (credit-based)</td>\n      <td>—</td>\n      <td>—</td>\n      <td>0.0330</td>\n      <td>0.0165 (Metagrapho API)</td>\n    </tr>\n  </tbody>\n</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     }
    }
   ],
   "source": "# =============================================================================\n# 6b. API Cost Reference Table\n# =============================================================================\n# Per-page costs are computed from ACTUAL token usage recorded in the output\n# JSONL files (raw_response.usage.input_tokens / output_tokens), not from\n# assumed averages. Token counts are aggregated across all pages, categories,\n# and sources for each model. Output tokens for reasoning-enabled models\n# (run at medium budget) include thinking tokens billed at the standard rate.\n#\n# Transkribus: 0.5 credits/printed page at ~EUR 0.06/credit (add-on package),\n# converted at USD/EUR = 1.10; Metagrapho API applies a further 50 % discount.\n# =============================================================================\n\nfrom collections import defaultdict\n\n# Pricing per million tokens (USD), standard and batch (50 % discount)\nMODEL_PRICING = {\n    \"gpt_5.2_medium\": {\n        \"display\": \"GPT-5.2\",\n        \"provider\": \"OpenAI\",\n        \"input_per_m\":  1.75,\n        \"output_per_m\": 14.00,\n        \"batch_discount\": 0.50,\n    },\n    \"gpt_5_mini_medium\": {\n        \"display\": \"GPT-5 Mini\",\n        \"provider\": \"OpenAI\",\n        \"input_per_m\":  0.25,\n        \"output_per_m\": 2.00,\n        \"batch_discount\": 0.50,\n    },\n    \"gemini_3.0_pro_medium\": {\n        \"display\": \"Gemini 3 Pro Preview\",\n        \"provider\": \"Google\",\n        \"input_per_m\":  2.00,\n        \"output_per_m\": 12.00,\n        \"batch_discount\": 0.50,\n    },\n    \"gemini_3.0_flash\": {\n        \"display\": \"Gemini 3 Flash Preview\",\n        \"provider\": \"Google\",\n        \"input_per_m\":  0.50,\n        \"output_per_m\": 3.00,\n        \"batch_discount\": 0.50,\n    },\n    \"claude_sonnet_4.5_medium\": {\n        \"display\": \"Claude Sonnet 4.5\",\n        \"provider\": \"Anthropic\",\n        \"input_per_m\":  3.00,\n        \"output_per_m\": 15.00,\n        \"batch_discount\": 0.50,\n    },\n    \"claude_haiku_4.5_medium\": {\n        \"display\": \"Claude Haiku 4.5\",\n        \"provider\": \"Anthropic\",\n        \"input_per_m\":  1.00,\n        \"output_per_m\": 5.00,\n        \"batch_discount\": 0.50,\n    },\n    \"tesseract\": {\n        \"display\": \"Tesseract OCR\",\n        \"provider\": \"Open-source\",\n        \"input_per_m\":  0.00,\n        \"output_per_m\": 0.00,\n        \"batch_discount\": 0.00,\n    },\n}\n\n# Transkribus reference (not token-based)\nTRANSKRIBUS_CREDITS_PER_PRINTED_PAGE = 0.5\nTRANSKRIBUS_EUR_PER_CREDIT           = 0.06\nTRANSKRIBUS_USD_PER_EUR              = 1.10\nTRANSKRIBUS_API_DISCOUNT             = 0.50\n\n# =============================================================================\n# Extract actual token counts from output JSONL files\n# =============================================================================\ntoken_totals: Dict[str, Dict[str, int]] = defaultdict(\n    lambda: {\"input_tokens\": 0, \"output_tokens\": 0, \"pages\": 0}\n)\n\nfor category in CATEGORIES:\n    for model_key in discover_available_models(category):\n        if model_key not in MODEL_PRICING:\n            continue\n        model_out_dir = OUTPUT_PATH / category / model_key\n        for source_dir in model_out_dir.iterdir():\n            if not source_dir.is_dir():\n                continue\n            for jsonl_file in source_dir.glob(\"*.jsonl\"):\n                with open(jsonl_file, encoding=\"utf-8\") as f:\n                    for line in f:\n                        line = line.strip()\n                        if not line:\n                            continue\n                        try:\n                            record = json.loads(line)\n                        except json.JSONDecodeError:\n                            continue\n                        usage = record.get(\"raw_response\", {}).get(\"usage\", {})\n                        inp = usage.get(\"input_tokens\")\n                        out = usage.get(\"output_tokens\")\n                        if inp is None or out is None:\n                            continue\n                        token_totals[model_key][\"input_tokens\"] += inp\n                        token_totals[model_key][\"output_tokens\"] += out\n                        token_totals[model_key][\"pages\"] += 1\n\nprint(\"Token aggregates by model:\")\nprint(f\"  {'Model':<30} {'Pages':>6} {'Mean In/Page':>13} {'Mean Out/Page':>14}\")\nprint(\"-\" * 70)\nfor model_key, info in MODEL_PRICING.items():\n    t = token_totals[model_key]\n    if t[\"pages\"] > 0:\n        mean_in  = t[\"input_tokens\"]  / t[\"pages\"]\n        mean_out = t[\"output_tokens\"] / t[\"pages\"]\n        print(f\"  {info['display']:<30} {t['pages']:>6} {mean_in:>13.0f} {mean_out:>14.0f}\")\n    else:\n        print(f\"  {info['display']:<30} {'—':>6} {'—':>13} {'—':>14}\")\n\n# =============================================================================\n# Build cost DataFrame\n# =============================================================================\npricing_rows = []\nfor model_key, info in MODEL_PRICING.items():\n    t = token_totals[model_key]\n    pages = t[\"pages\"]\n    if pages > 0:\n        mean_in  = t[\"input_tokens\"]  / pages\n        mean_out = t[\"output_tokens\"] / pages\n    else:\n        mean_in = mean_out = 0.0\n\n    std_cost = (\n        info[\"input_per_m\"] * mean_in + info[\"output_per_m\"] * mean_out\n    ) / 1_000_000\n    bat_cost = std_cost * (1 - info[\"batch_discount\"])\n\n    pricing_rows.append({\n        \"Model\":                  info[\"display\"],\n        \"Provider\":               info[\"provider\"],\n        \"Input ($/M tok)\":  f\"{info['input_per_m']:.2f}\"  if info[\"input_per_m\"]  > 0 else \"—\",\n        \"Output ($/M tok)\": f\"{info['output_per_m']:.2f}\" if info[\"output_per_m\"] > 0 else \"—\",\n        \"Avg Input Tok/Page\":  f\"{mean_in:.0f}\"  if pages > 0 else \"—\",\n        \"Avg Output Tok/Page\": f\"{mean_out:.0f}\" if pages > 0 else \"—\",\n        \"$/page (standard)\":    f\"{std_cost:.5f}\" if std_cost > 0 else \"0 (free)\",\n        \"$/page (batch 50%)\": f\"{bat_cost:.5f}\" if bat_cost > 0 else \"0 (free)\",\n    })\n\n# Transkribus row\ntranskr_std = (\n    TRANSKRIBUS_CREDITS_PER_PRINTED_PAGE\n    * TRANSKRIBUS_EUR_PER_CREDIT\n    * TRANSKRIBUS_USD_PER_EUR\n)\ntranskr_api = transkr_std * (1 - TRANSKRIBUS_API_DISCOUNT)\npricing_rows.append({\n    \"Model\":               \"Transkribus (printed)\",\n    \"Provider\":            \"Transkribus\",\n    \"Input ($/M tok)\":     \"N/A (credit-based)\",\n    \"Output ($/M tok)\":    \"N/A (credit-based)\",\n    \"Avg Input Tok/Page\":  \"—\",\n    \"Avg Output Tok/Page\": \"—\",\n    \"$/page (standard)\":   f\"{transkr_std:.4f}\",\n    \"$/page (batch 50%)\":  f\"{transkr_api:.4f} (Metagrapho API)\",\n})\n\ndf_cost = pd.DataFrame(pricing_rows)\n\ndisplay(HTML(\n    \"<h4>Table 6: API Cost Reference — Token Pricing and Actual Per-Page Cost</h4>\"\n    \"<p><em>Per-page costs computed from actual token usage recorded in the JSONL \"\n    \"output files. Output token counts for reasoning-enabled models (GPT-5.2, GPT-5 Mini, \"\n    \"Gemini 3 Pro Preview, Claude Sonnet 4.5, Claude Haiku 4.5 — all run at medium \"\n    \"reasoning budget) include reasoning/thinking tokens billed at the standard output \"\n    \"rate. All LLM providers offer a 50% batch-processing discount. \"\n    \"Transkribus estimate: 0.5 credits per printed page at ~\\u20ac0.06/credit (add-on \"\n    \"package), converted at USD/EUR \\u2248 1.10; Metagrapho API applies a further 50% \"\n    \"credit reduction. Prices as of February 2026.</em></p>\"\n))\ndisplay(HTML(df_cost.to_html(index=False)))\n\nif SAVE_TABLES_LATEX:\n    latex_path = LATEX_OUTPUT_DIR / \"table_06_cost_reference.tex\"\n    df_cost.to_latex(\n        latex_path, index=False,\n        caption=(\n            \"API cost reference for all transcription models (February 2026). \"\n            \"Per-page costs computed from actual token usage recorded in the JSONL \"\n            \"output files. Output token counts for models run at medium reasoning budget \"\n            \"include reasoning/thinking tokens billed at the standard output rate. \"\n            \"Tesseract OCR is open-source and incurs no API cost. Transkribus costs are \"\n            \"credit-based (0.5 credits per printed page at \\\\texteuro{}0.06 per credit; \"\n            \"Metagrapho API applies a further 50\\\\% credit reduction).\"\n        ),\n        label=\"tab:cost_reference\",\n    )\n    print(f\"Saved: {latex_path}\")\n\n# =============================================================================\n# Comparison: old estimated vs. actual costs\n# =============================================================================\nASSUMED_INPUT  = 2_000\nASSUMED_OUTPUT =   700\n\nprint(\"\\nCost comparison — estimated (2,000 in / 700 out) vs. actual:\")\nprint(f\"  {'Model':<25} {'Est. $/pg (std)':>16} {'Act. $/pg (std)':>16} {'Ratio':>7}\")\nprint(\"-\" * 70)\nfor row in pricing_rows[:-1]:  # skip Transkribus\n    model_key = next(\n        k for k, v in MODEL_PRICING.items() if v[\"display\"] == row[\"Model\"]\n    )\n    info = MODEL_PRICING[model_key]\n    est = (\n        info[\"input_per_m\"] * ASSUMED_INPUT + info[\"output_per_m\"] * ASSUMED_OUTPUT\n    ) / 1_000_000\n    act_str = row[\"$/page (standard)\"]\n    act = float(act_str) if act_str not in (\"0 (free)\", \"—\") else 0.0\n    ratio = (act / est) if est > 0 else float(\"nan\")\n    print(f\"  {row['Model']:<25} {est:>16.5f} {act:>16.5f} {ratio:>7.1f}x\")\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualization (Optional)\n",
    "\n",
    "This section produces a compact figure comparing model error rates.\n",
    "\n",
    "### What is plotted\n",
    "If `matplotlib` is available and `overall_model_metrics` has data, the code:\n",
    "- Sorts models by overall CER for consistent ordering.\n",
    "- Plots horizontal bar charts for:\n",
    "  - CER (percent)\n",
    "  - WER (percent)\n",
    "\n",
    "### Files written\n",
    "- A timestamped PNG figure is saved to the reports directory for quick viewing and sharing.\n",
    "- If `SAVE_TABLES_LATEX = True`, a PDF version is also saved to `LATEX_OUTPUT_DIR` for LaTeX workflows.\n",
    "\n",
    "### Output produced\n",
    "- The figure is displayed inline in the notebook.\n",
    "- **Table 6**: A small performance summary table (sorted by CER) is displayed inline and optionally exported as TeX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T09:47:19.289463Z",
     "iopub.status.busy": "2026-02-21T09:47:19.288772Z",
     "iopub.status.idle": "2026-02-21T09:47:22.099745Z",
     "shell.execute_reply": "2026-02-21T09:47:22.097915Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chart saved: C:\\Users\\pagoetz\\PycharmProjects\\ChronoTranscriber\\eval\\reports\\eval_chart_20260221_104719.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF chart saved: C:\\Users\\pagoetz\\PycharmProjects\\ChronoTranscriber\\eval\\reports\\latex_tables\\figure_01_error_rates.pdf\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h4>Table 6: Model Performance Summary (Sorted by CER)</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Model</th>\n",
       "      <th>CER (%)</th>\n",
       "      <th>WER (%)</th>\n",
       "      <th>CER Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>gemini_3.0_pro_medium</td>\n",
       "      <td>6.19</td>\n",
       "      <td>18.11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>gpt_5.2_medium</td>\n",
       "      <td>7.48</td>\n",
       "      <td>21.38</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>claude_sonnet_4.5_medium</td>\n",
       "      <td>7.65</td>\n",
       "      <td>19.22</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>gemini_3.0_flash</td>\n",
       "      <td>8.31</td>\n",
       "      <td>19.38</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>claude_haiku_4.5_medium</td>\n",
       "      <td>9.77</td>\n",
       "      <td>27.78</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>gpt_5_mini_medium</td>\n",
       "      <td>21.11</td>\n",
       "      <td>41.04</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tesseract</td>\n",
       "      <td>57.30</td>\n",
       "      <td>86.50</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:\\Users\\pagoetz\\PycharmProjects\\ChronoTranscriber\\eval\\reports\\latex_tables\\table_06_performance_summary.tex\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 7. Visualization (Optional)\n",
    "# =============================================================================\n",
    "\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "\n",
    "    PLOT_AVAILABLE = True\n",
    "except ImportError:\n",
    "    PLOT_AVAILABLE = False\n",
    "    print(\"matplotlib not available - skipping visualizations\")\n",
    "    print(\"Install with: pip install matplotlib\")\n",
    "\n",
    "if PLOT_AVAILABLE and overall_model_metrics:\n",
    "    # Prepare data - sort by CER for consistent ordering\n",
    "    ranked = sorted(overall_model_metrics.items(), key=lambda x: x[1].cer)\n",
    "    models = [m[0] for m in ranked]\n",
    "    cer_values = [m[1].cer * 100 for m in ranked]\n",
    "    wer_values = [m[1].wer * 100 for m in ranked]\n",
    "\n",
    "    # Create figure\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "    # CER bar chart\n",
    "    ax1 = axes[0]\n",
    "    bars1 = ax1.barh(models, cer_values, color='steelblue')\n",
    "    ax1.set_xlabel('Character Error Rate (%)')\n",
    "    ax1.set_title('CER by Model (Lower is Better)')\n",
    "    ax1.bar_label(bars1, fmt='%.2f%%', padding=3)\n",
    "    ax1.set_xlim(0, max(cer_values) * 1.25 if cer_values else 10)\n",
    "\n",
    "    # WER bar chart\n",
    "    ax2 = axes[1]\n",
    "    bars2 = ax2.barh(models, wer_values, color='darkorange')\n",
    "    ax2.set_xlabel('Word Error Rate (%)')\n",
    "    ax2.set_title('WER by Model (Lower is Better)')\n",
    "    ax2.bar_label(bars2, fmt='%.2f%%', padding=3)\n",
    "    ax2.set_xlim(0, max(wer_values) * 1.25 if wer_values else 10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save figure\n",
    "    fig_path = REPORTS_PATH / f\"eval_chart_{timestamp}.png\"\n",
    "    plt.savefig(fig_path, dpi=150, bbox_inches='tight')\n",
    "    print(f\"Chart saved: {fig_path}\")\n",
    "\n",
    "    # Also save as PDF for LaTeX inclusion\n",
    "    if SAVE_TABLES_LATEX:\n",
    "        pdf_path = LATEX_OUTPUT_DIR / f\"figure_01_error_rates.pdf\"\n",
    "        plt.savefig(pdf_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"PDF chart saved: {pdf_path}\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # =============================================================================\n",
    "    # Create summary statistics table for visualization\n",
    "    # =============================================================================\n",
    "    viz_stats = pd.DataFrame({\n",
    "        'Model': models,\n",
    "        'CER (%)': [f'{v:.2f}' for v in cer_values],\n",
    "        'WER (%)': [f'{v:.2f}' for v in wer_values],\n",
    "        'CER Rank': range(1, len(models) + 1),\n",
    "    })\n",
    "\n",
    "    display(HTML('<h4>Table 6: Model Performance Summary (Sorted by CER)</h4>'))\n",
    "    display(HTML(viz_stats.to_html(index=False)))\n",
    "\n",
    "    if SAVE_TABLES_LATEX:\n",
    "        latex_path = LATEX_OUTPUT_DIR / 'table_06_performance_summary.tex'\n",
    "        viz_stats.to_latex(latex_path, index=False,\n",
    "                           caption='Model Performance Summary Sorted by Character Error Rate',\n",
    "                           label='tab:performance_summary')\n",
    "        print(f'Saved: {latex_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "### Ground Truth Workflow\n",
    "\n",
    "1. **Extract transcriptions for editing**\n",
    "   ```bash\n",
    "   python main/prepare_ground_truth.py --extract --input eval/test_data/output/{category}/{model}\n",
    "   ```\n",
    "\n",
    "2. **Edit the generated `_editable.txt` files**\n",
    "   - Each page is marked with `=== page NNN ===`\n",
    "   - Correct transcription errors directly in the text\n",
    "   - Use `[NO TRANSCRIBABLE TEXT]` for blank pages\n",
    "   - Use `[TRANSCRIPTION NOT POSSIBLE]` for illegible pages\n",
    "\n",
    "3. **Apply corrections to create ground truth**\n",
    "   ```bash\n",
    "   python main/prepare_ground_truth.py --apply --input eval/test_data/output/{category}/{model}\n",
    "   ```\n",
    "\n",
    "4. **Check ground truth status**\n",
    "   ```bash\n",
    "   python main/prepare_ground_truth.py --status\n",
    "   ```\n",
    "\n",
    "### Expected Directory Structure\n",
    "```\n",
    "eval/\n",
    "├── test_data/\n",
    "│   ├── input/                    # Source documents\n",
    "│   │   ├── address_books/\n",
    "│   │   ├── bibliography/\n",
    "│   │   └── military_records/\n",
    "│   ├── output/                   # Model outputs (JSONL per source)\n",
    "│   │   └── {category}/\n",
    "│   │       └── {model_name}/\n",
    "│   │           └── {source}/\n",
    "│   │               └── {source}.jsonl\n",
    "│   └── ground_truth/             # Corrected transcriptions (JSONL)\n",
    "│       └── {category}/\n",
    "│           └── {source}.jsonl\n",
    "└── reports/                      # Generated evaluation reports\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}