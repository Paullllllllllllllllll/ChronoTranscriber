from __future__ import annotations

import json
import random
from pathlib import Path
from typing import Any, Dict, Iterable, List, Optional, Sequence, Tuple

from fine_tuning.jsonl_io import iter_jsonl, write_jsonl


DEFAULT_SYSTEM_PROMPT = (
    "You are an expert document transcriber. "
    "Transcribe the text visible in the provided image accurately. "
    "Return only valid JSON following the provided schema."
)


def _canonical_json(obj: Dict[str, Any]) -> str:
    """Convert a dictionary to canonical JSON string."""
    return json.dumps(obj, ensure_ascii=False, separators=(",", ":"), sort_keys=True)


def build_sft_examples(
    annotation_records: Iterable[Dict[str, Any]],
    *,
    system_prompt: str,
) -> List[Dict[str, Any]]:
    """
    Build SFT examples from annotation records.
    
    Note: This builds text-only SFT examples. For vision SFT with images,
    use build_openai_vision_sft_jsonl.py instead.
    
    Args:
        annotation_records: Iterable of annotation records with 'output' field.
        system_prompt: The system prompt to use.
        
    Returns:
        List of SFT examples in OpenAI chat format.
    """
    examples: List[Dict[str, Any]] = []
    
    for rec in annotation_records:
        output_obj = rec.get("output")
        if not isinstance(output_obj, dict):
            raise ValueError("Annotation record missing 'output' JSON object")

        # For text-based SFT (non-vision), we include transcription as user content
        # This is useful for training on text corrections
        transcription = output_obj.get("transcription", "")
        if transcription is None:
            transcription = ""
        
        # Build user message describing what was transcribed
        image_name = rec.get("image_name", "unknown")
        user_content = f"[Transcription from: {image_name}]\n\n{transcription}"

        examples.append(
            {
                "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_content},
                    {"role": "assistant", "content": _canonical_json(output_obj)},
                ]
            }
        )
    
    return examples


def train_val_split(
    examples: Sequence[Dict[str, Any]],
    *,
    val_ratio: float,
    seed: int,
) -> Tuple[List[Dict[str, Any]], List[Dict[str, Any]]]:
    """
    Split examples into training and validation sets.
    
    Args:
        examples: Sequence of examples to split.
        val_ratio: Fraction of examples to use for validation (0 to 1).
        seed: Random seed for reproducibility.
        
    Returns:
        Tuple of (train_examples, val_examples).
    """
    if val_ratio < 0 or val_ratio >= 1:
        raise ValueError("val_ratio must be in [0, 1)")

    rng = random.Random(seed)
    indices = list(range(len(examples)))
    rng.shuffle(indices)

    val_count = int(len(examples) * val_ratio)
    val_idx = set(indices[:val_count])

    train: List[Dict[str, Any]] = []
    val: List[Dict[str, Any]] = []
    
    for i, ex in enumerate(examples):
        if i in val_idx:
            val.append(ex)
        else:
            train.append(ex)

    return train, val


def build_sft_dataset(
    *,
    annotations_paths: List[Path],
    out_dir: Path,
    system_prompt: Optional[str] = None,
    val_ratio: float = 0.1,
    seed: int = 0,
) -> Tuple[Path, Optional[Path]]:
    """
    Build an SFT dataset from annotation JSONL files.
    
    Args:
        annotations_paths: List of paths to annotation JSONL files.
        out_dir: Output directory for the dataset.
        system_prompt: System prompt to use (defaults to DEFAULT_SYSTEM_PROMPT).
        val_ratio: Fraction of examples for validation set.
        seed: Random seed for train/val split.
        
    Returns:
        Tuple of (train_path, val_path). val_path is None if val set is empty.
    """
    if system_prompt is None:
        system_prompt = DEFAULT_SYSTEM_PROMPT

    records: List[Dict[str, Any]] = []
    for p in annotations_paths:
        for rec in iter_jsonl(p):
            records.append(rec)

    examples = build_sft_examples(records, system_prompt=system_prompt)
    train, val = train_val_split(examples, val_ratio=val_ratio, seed=seed)

    out_dir.mkdir(parents=True, exist_ok=True)
    train_path = out_dir / "train.jsonl"
    write_jsonl(train_path, train)

    val_path: Optional[Path]
    if val:
        val_path = out_dir / "val.jsonl"
        write_jsonl(val_path, val)
    else:
        val_path = None

    return train_path, val_path
